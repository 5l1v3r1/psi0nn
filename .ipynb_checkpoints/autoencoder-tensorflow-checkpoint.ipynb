{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try solving for MPS coefficients of GHZ state with an Autoencoder\n",
    "\n",
    "Sam Greydanus. March 2017. MIT License.\n",
    "\n",
    "Brief explanation and live demo of autoencoder [here](https://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html). Wikipedia article [here](https://en.wikipedia.org/wiki/Autoencoder).\n",
    "\n",
    "<img src=\"static/autoencoder.png\" alt=\"Finite DMRG base case\" style=\"width: 40%;\"/>\n",
    "\n",
    "I modify the decoder part. Instead of being a neural network, I use the definition of reconstructing a state using MPS coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "Simple functions that might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def llprint(message):\n",
    "    sys.stdout.write(message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def baseN(num, b, numerals=\"0123456789abcdefghijklmnopqrstuvwxyz\"):\n",
    "    return ((num == 0) and numerals[0]) or (baseN(num // b, b, numerals).lstrip(numerals[0]) + numerals[num % b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 'decode' portion\n",
    "These functions are written for TensorFlow variables. TensorFlow uses lazy execution, meaning that it builds an optimized computational graph and only executes the operations in that graph after a `run` or `eval` request. See https://www.tensorflow.org/get_started/mnist/mechanics for a good introduction to TensorFlow mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mps2state(A_list):\n",
    "    '''given a list of mps coefficients, returns the state of the full system.\n",
    "    The input A_list is indexed according to A_list[{local state}][{local site}].'''\n",
    "    d = len(A_list) # number of possible states\n",
    "    chi = len(A_list[0]) # number of possible sites\n",
    "    c = [] # the state\n",
    "    for sys_state in range(d**chi): # loop over \n",
    "        ix = baseN(sys_state, d).zfill(len(A_list[0]))\n",
    "        for site in range(chi):\n",
    "            site_state = A_list[int(ix[site])][site]\n",
    "            prod = site_state if site is 0 else tf.matmul(prod, site_state) # matrix multiplication (contract tensors)\n",
    "        c.append(tf.trace(prod))\n",
    "    return tf.stack(c)\n",
    "\n",
    "def coeff2mps(coeff, d, chi):\n",
    "    '''given a vector of coefficients of length chi*d^3, reshapes them into an A_list\n",
    "    that can be passed to mps2state function above'''\n",
    "    print(\"HIHIHIHIH:\", coeff.get_shape())\n",
    "    splits = tf.split(coeff,d*chi,axis=1)\n",
    "    print(\"HIHIHIHIH:\", splits[0].get_shape())\n",
    "    dxd_splits = [tf.reshape(c, [d,d]) for c in splits]\n",
    "    A_list = [dxd_splits[d_i*chi:(1+d_i)*chi] for d_i in range(d)]\n",
    "    return A_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 'encode' portion\n",
    "We'll use a 2-layer neural network with 512 hidden units and [elu activations](https://arxiv.org/abs/1511.07289)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "lr = 5e-4 # learning rate\n",
    "batch_size = 1 # batch size for minibatch gradient descent\n",
    "steps = 50000  # total steps of gradient descent\n",
    "global_step = 0 # keeps track of current step of gradient descent\n",
    "d = 2 # number of quantum states available to each site\n",
    "chi = 3 # number of sites (ie electrons)\n",
    "\n",
    "X_dim = d**chi # autoencoder input dimensionality\n",
    "h2_dim = h1_dim = 512 # dimensionality of hidden layer(s)\n",
    "h3_dim = d*chi*d*d # dimensionality of MPS 'coeff' vector\n",
    "init = tf.truncated_normal_initializer(stddev=0.075, dtype=tf.float32) # says how to initialize the NN weights + biases\n",
    "\n",
    "save_path = \"saved_models/model.ckpt\"\n",
    "save_every = 10000\n",
    "save_model = True\n",
    "\n",
    "# trainable parameters\n",
    "#      => keep them in a dictionary for organizational purposes\n",
    "params = {}\n",
    "params['W1'] = tf.get_variable(\"W1\", [X_dim, h1_dim], initializer=init)\n",
    "params['b1'] = tf.get_variable(\"b1\", [h1_dim], initializer=init)\n",
    "params['W2'] = tf.get_variable(\"W2\", [h1_dim, h2_dim], initializer=init)\n",
    "params['b2'] = tf.get_variable(\"b2\", [h2_dim], initializer=init)\n",
    "\n",
    "params['W3'] = tf.get_variable(\"W3\", [h2_dim, h3_dim], initializer=init)\n",
    "params['b3'] = tf.get_variable(\"b3\", [h3_dim], initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full Autoencoder forward pass\n",
    "First encode with the neural network, then decode using the definition of MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def nn_forward(X):\n",
    "#     # neural network forward pass\n",
    "#     z1 = tf.matmul(X, params['W1']) + params['b1']\n",
    "#     h1 = tf.nn.elu(z1) # elu nonlinear activation\n",
    "#     z2 = tf.matmul(h1, params['W2']) + params['b2']\n",
    "#     return tf.nn.sigmoid(z2) # we want all of the predicted MPS coefficients to be positive\n",
    "\n",
    "def nn_forward(X):\n",
    "    # neural network forward pass\n",
    "    z1 = tf.matmul(X, params['W1']) + params['b1']\n",
    "    h1 = tf.nn.tanh(z1) # elu nonlinear activation\n",
    "#     h1 = tf.nn.dropout(h1, .8)\n",
    "    z2 = tf.matmul(h1, params['W2']) + params['b2']\n",
    "    h2 = tf.nn.tanh(z2)\n",
    "    z3 = tf.matmul(h2, params['W3']) + params['b3']\n",
    "    return tf.nn.sigmoid(z3) # we want all of the predicted MPS coefficients to be positive\n",
    "\n",
    "def forward(X):\n",
    "    '''defines one forward pass of the neural network encoder. The input is the\n",
    "    full-dimension state vector of the system and the output is an attempt at\n",
    "    reconstructing the input vector after compressing it as a set of MPS coefficients'''\n",
    "    coeff = nn_forward(X)\n",
    "    \n",
    "    A_list = coeff2mps(coeff, d, chi) # repackage output vector as a list of A matrices\n",
    "    psi_hat = mps2state(A_list) # reconstruct the original state vector from these A matrices by definition of MPS\n",
    "    return psi_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow mechanics\n",
    "These are a set of TensorFlow utilities that we'll need to train/interact with our autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIHIHIHIH: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "# We will pass numpy vectors of the same dimensionality to placeholders.\n",
    "# Think of them as entrypoints to the computational graph\n",
    "X = tf.placeholder(tf.float32, [batch_size, X_dim])\n",
    "y = tf.placeholder(tf.float32, [batch_size, X_dim])\n",
    "y_hat = forward(X) # forward pass of the autoencoder\n",
    "loss = tf.nn.l2_loss( y - y_hat ) / X_dim * 1e4 # loss function (we want to minimize this value)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr) # The Adam optimizer is a fancy sibling of stochastic gradient descent\n",
    "grads = optimizer.compute_gradients(loss, \\\n",
    "                                var_list=tf.trainable_variables()) # get derivatives on all trainable variables\n",
    "train_op = optimizer.apply_gradients(grads) # apply gradients (update trainable variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have built the full computational graph. In order to execute it, we need to start a session. Sessions hold all the state information of a TensorFlow model (e.g. parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession() # start an interactive session\n",
    "tf.global_variables_initializer().run() # initialize all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model overview\n",
    "Let's take a look at the trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model overview:\n",
      "\tvariable \"W1:0\" has 4096 parameters\n",
      "\tvariable \"b1:0\" has 512 parameters\n",
      "\tvariable \"W2:0\" has 262144 parameters\n",
      "\tvariable \"b2:0\" has 512 parameters\n",
      "\tvariable \"W3:0\" has 12288 parameters\n",
      "\tvariable \"b3:0\" has 24 parameters\n",
      "Total of 279576 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0 ; print(\"Model overview:\")\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    print('\\tvariable \"{}\" has {} parameters' \\\n",
    "        .format(variable.name, variable_parameters))\n",
    "    total_parameters += variable_parameters\n",
    "print(\"Total of {} parameters\".format(total_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "In order to train the model, we need data. In this case, I'll just choose each example state vector to be a random d^chi vector such that the dot product of the vector with its conjugate transpose is normalized (a necessary property of a state vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def next_batch(d, chi, batch_size):\n",
    "    psi = np.random.rand(1, d**chi)\n",
    "    psi /= np.sqrt(np.dot(psi, psi.T))\n",
    "    return psi\n",
    "k = next_batch(d, chi, 1)\n",
    "print(k.shape) ; print(np.dot(k, k.conjugate().T)[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model\n",
    "...if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model: saved_models/model.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "load_was_success = True # yes, I'm being optimistic\n",
    "try:\n",
    "    save_dir = '/'.join(save_path.split('/')[:-1])\n",
    "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "    load_path = ckpt.model_checkpoint_path\n",
    "    saver.restore(sess, load_path)\n",
    "except:\n",
    "    print(\"no saved model to load.\")\n",
    "    load_was_success = False\n",
    "else:\n",
    "    print(\"loaded model: {}\".format(load_path))\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    global_step = int(load_path.split('-')[-1]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Display the loss every so often. It should be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tloss: 0.2621\n",
      "\n",
      "\tloss: 0.2875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-499e5a0386a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_X\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# pair each placeholder with a numpy matrix of the same dimensions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstep_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run the loss and train_op (we don't care what train_op returns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "for i in range(global_step+1, 100000):\n",
    "#     llprint(\"\\rIteration {}/{}\".format(i, steps))\n",
    "    \n",
    "    np_X = next_batch(d, chi, batch_size) # get a random state vector\n",
    "\n",
    "    fetch = [loss, train_op] # list of all the TensorFlow variables and operations we want to fetch from the model\n",
    "    feed = {X: np_X, y: np_X} # pair each placeholder with a numpy matrix of the same dimensions.\n",
    "\n",
    "    step_loss, _ = sess.run(fetch, feed_dict=feed) # run the loss and train_op (we don't care what train_op returns)\n",
    "    loss_history.append(step_loss)\n",
    "    \n",
    "    global_step = i\n",
    "    if i % 1000 == 0:\n",
    "        llprint(\"\\n\\tloss: {:03.4f}\\n\".format(np.mean(loss_history))) # show the average loss for the past several\n",
    "        loss_history = []\n",
    "    if save_model and i % save_every == 0 and i is not 0:\n",
    "        llprint(\"\\n\\tSAVING MODEL\\n\")\n",
    "        saver.save(sess, save_path, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect autoencoded MPS for GHZ state\n",
    "The closer the two are, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678  0.          0.          0.          0.          0.          0.\n",
      "  0.70710678]\n",
      "[ 0.71343881  0.01980652  0.03925033  0.0219753   0.01986407  0.03134814\n",
      "  0.0232317   0.66967791]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAB3CAYAAABv/BgkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110c93e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAB4CAYAAACeqqrxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzAq5wWBmZmaF/h8kRX8MySdTGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114a3ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the GHZ state\n",
    "k = np.zeros((1, d**chi))\n",
    "k[:,0] = np.sqrt(1/2.)\n",
    "k[:,-1] = np.sqrt(1/2.)\n",
    "\n",
    "# feed GHZ state through model (try to reconstruct it from predicted MPS coefficients)\n",
    "feed = {X: k}\n",
    "k_hat = y_hat.eval(feed) # get reconstructed state\n",
    "\n",
    "# compare the actual state with the reconstructed state\n",
    "print k.ravel()\n",
    "print k_hat.ravel()\n",
    "\n",
    "# plot the vectors so it's easier to visualize\n",
    "plt.figure(0) ; plt.imshow(k, interpolation='none') ; plt.title('true $\\psi$')\n",
    "plt.figure(1) ; plt.imshow(np.stack([k_hat]), interpolation='none') ; plt.title('MPS autoencoded $\\psi$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect actual MPS coeff\n",
    "Just run the encoding portion of the autoencoder so that we can inspect how the model is encoding the GHZ state (and whether that encoding matches theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mps(X):\n",
    "    '''This is the encoder portion of the autencoder. It returns MPS coefficients\n",
    "    which we can inspect to see whether the models encoding matches theory'''\n",
    "    coeff = nn_forward(X)\n",
    "    A_list = coeff2mps(coeff, d, chi)\n",
    "    return A_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the MPS coefficients for a given state and site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88406068  0.1393687 ]\n",
      " [ 0.39301249  0.001     ]]\n"
     ]
    }
   ],
   "source": [
    "# get the model's prediction\n",
    "state = 1 # there are a total of d states\n",
    "site = 0 # there are a total of chi sites\n",
    "print np.clip(get_mps(X)[state][site].eval(feed), 1e-3, 1-1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstate 0\n",
      "\t\tsite 0\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.001       0.49572003]\n",
      "\t\t\t [ 0.16780828  0.89127642]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\t\tsite 1\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.05490946  0.03369491]\n",
      "\t\t\t [ 0.86849374  0.04614897]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\t\tsite 2\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.0012595   0.91013998]\n",
      "\t\t\t [ 0.001       0.001     ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\tstate 1\n",
      "\t\tsite 0\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.88406068  0.1393687 ]\n",
      "\t\t\t [ 0.39301249  0.001     ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n",
      "\t\tsite 1\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.06472719  0.86715662]\n",
      "\t\t\t [ 0.03617162  0.05113694]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n",
      "\t\tsite 2\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.001       0.001     ]\n",
      "\t\t\t [ 0.86542886  0.001     ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# construct the ideal MPS for the GHZ state\n",
    "A_list = [] # MPS list of coefficients\n",
    "for state in range(d):\n",
    "    A_list.append([])\n",
    "    for site in range(chi):\n",
    "        A = np.zeros((d,d)) ; A[state,state] = 1\n",
    "        A_list[state].append(A)\n",
    "        \n",
    "# compare\n",
    "for j in range(d):\n",
    "    print\"\\tstate %i\" % j\n",
    "    for k in range(chi):\n",
    "        print \"\\t\\tsite {}\".format(k)\n",
    "        pred_A_list = np.clip(get_mps(X)[j][k].eval(feed), 1e-3, 1-1e-3)\n",
    "        print('\\t\\t\\tmodel:\\n\\t\\t\\t' + str(pred_A_list).replace('\\n', '\\n\\t\\t\\t'))\n",
    "        print('\\t\\t\\tmodel:\\n\\t\\t\\t' + str(A_list[j][k]).replace('\\n', '\\n\\t\\t\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
