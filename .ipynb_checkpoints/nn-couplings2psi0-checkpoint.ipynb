{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for estimating ground state, $\\psi_0$, from $H_{sys}$ coupling terms\n",
    "Sam Greydanus. 24 May 2017. MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import *\n",
    "import os, copy, glob\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import kron, identity\n",
    "\n",
    "np.random.seed(seed=123) # for reproducibility\n",
    "ms = torch.manual_seed(123) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "global_step = 0\n",
    "print_every = 100\n",
    "save_dir = 'couplings2psi0-models'\n",
    "checkpoint_steps = [1, 10,30,100,300,1000,3000,10000,30000,100000,300000]\n",
    "checkpoint_steps += [250, 500, 1000, 2000, 4000, 16000, 64000, 128000]\n",
    "total_steps = max(checkpoint_steps)\n",
    "d = 2\n",
    "N = 4\n",
    "D_side = d**N\n",
    "D_img = D_side**2\n",
    "D_hidden = 512\n",
    "batch_size = 16\n",
    "num_couplings = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "Use the same free site as we've been using for DMRG runs. Change the coupling constants `J` and `Jz` randomly, try to estimate change in energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FreeSite():\n",
    "    def __init__(self, c, rand=False):\n",
    "        self.length = 1 # length\n",
    "        self.ops = ops = {}\n",
    "        J = c['J'] if 'J' in c.keys() else np.random.randn()\n",
    "        Jz = c['Jz'] if 'Jz' in c.keys() else np.random.randn()\n",
    "        alpha1 = c['alpha1'] if 'alpha1' in c.keys() else np.random.randn()\n",
    "        alpha1 = c['alpha2'] if 'alpha2' in c.keys() else np.random.randn()\n",
    "        beta = c['beta'] if 'beta' in c.keys() else np.random.randn()\n",
    "        gamma = c['gamma'] if 'gamma' in c.keys() else np.random.randn()\n",
    "        \n",
    "        self.c = c = {'J':J, 'Jz':Jz, 'alpha1':alpha1, 'alpha2':alpha2, \\\n",
    "                          'beta':beta, 'gamma':gamma}\n",
    "        self.all_couplings = list(c.values())\n",
    "        \n",
    "        # build operator dictionary\n",
    "        ops[\"H\"] = np.zeros((2,2)) # local fields are 0\n",
    "        ops[\"Sxz\"] = np.array([[0.5, 0], [0, -0.5]]) # z spin (S^z) operator\n",
    "        ops[\"Sp\"] = np.array([[0.0, 1.0], [0.0, 0.0]]) # raising (S^+) operator\n",
    "        \n",
    "        if rand:\n",
    "            ops[\"Sxz\"] = np.array([[c['alpha1'], 0], [0, -c['alpha2']]]) + \\\n",
    "                    np.array([[0, c['beta']], [c['beta'], 0]])\n",
    "            ops[\"Sp\"] *= c['gamma']\n",
    "    \n",
    "    def get_dim(self):\n",
    "        return list(self.ops.values())[0].shape[0] # all ops should have same dimensionality\n",
    "        \n",
    "    def enlarge(self, site):\n",
    "        '''Enlarge block by a single site'''\n",
    "        \n",
    "        D1, H1, Sxz1, Sp1 = self.get_dim(), self.ops['H'], self.ops['Sxz'], self.ops['Sp'] # this block\n",
    "        D2, H2, Sxz2, Sp2 = site.get_dim(), site.ops['H'], site.ops['Sxz'], site.ops['Sp'] # another block (ie free site)\n",
    "\n",
    "        enlarged = copy.deepcopy(self)\n",
    "        enlarged.length += site.length\n",
    "        enlarged.all_couplings += site.all_couplings\n",
    "        ops = enlarged.ops\n",
    "\n",
    "        ops['H'] = kron(H1, identity(D2)) + kron(identity(D1), H2) + self.interaction_H(site)\n",
    "        ops['Sxz'] = kron(identity(D1), Sxz2)\n",
    "        ops['Sp'] = kron(identity(D1), Sp2)\n",
    "\n",
    "        return enlarged\n",
    "    \n",
    "    def interaction_H(self, site):\n",
    "        '''Given another block, returns two-site term in the \n",
    "        Hamiltonain that joins the two sites.'''\n",
    "        Sxz1, Sp1 = self.ops[\"Sxz\"], self.ops[\"Sp\"] # this block\n",
    "        Sxz2, Sp2 = site.ops[\"Sxz\"], site.ops[\"Sp\"] # other block\n",
    "        \n",
    "        join_Sp = (self.c['J']/2)*(kron(Sp1, Sp2.conjugate().transpose()) + kron(Sp1.conjugate().transpose(), Sp2))\n",
    "        join_Sxz = self.c['Jz']*kron(Sxz1, Sxz2)\n",
    "        return (join_Sp + join_Sxz)\n",
    "    \n",
    "    def rotate_ops(self, transformation_matrix):\n",
    "        # rotate and truncate each operator.\n",
    "        new_ops = {}\n",
    "        for name, op in self.ops.items():\n",
    "            new_ops[name] = self.rotate_and_truncate(op, transformation_matrix)\n",
    "        self.ops = new_ops\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate_and_truncate(S, O):\n",
    "        '''Transforms the operator to a new (possibly truncated) basis'''\n",
    "        return O.conjugate().transpose().dot(S.dot(O)) # eqn 7 in arXiv:cond-mat/0603842v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ham(c, rand=False):\n",
    "    sys = FreeSite(c, rand=rand)\n",
    "    for _ in range(N-1):\n",
    "        fs = FreeSite(c, rand=rand)\n",
    "        sys = sys.enlarge(fs)\n",
    "    return sys.all_couplings, sys.ops['H'].todense()\n",
    "\n",
    "def next_batch(D, batch_size, just_ground=True):\n",
    "    couplings = {'alpha1':1, 'alpha2':1, 'beta':1, 'gamma':1}\n",
    "    c_list = [] ; H_list = [] ; e0_list = [] ; psi0_list = []\n",
    "    e1_list = [] ; psi1_list = [] ; e2_list = [] ; psi2_list = []\n",
    "    for _ in range(batch_size):\n",
    "        c, H = ham(couplings, rand=True)\n",
    "        e0, psi0 = eigsh(H,k=3, which=\"SA\")\n",
    "        c_list.append(c) ; H_list.append(np.asarray(H).ravel()) ; e0_list.append(e0[0].ravel()) ; psi0_list.append(psi0[:,0].ravel())\n",
    "        if not just_ground:\n",
    "            e1_list.append(e0[1].ravel()) ; psi1_list.append(psi0[:,1].ravel())\n",
    "            e2_list.append(e0[2].ravel()) ; psi2_list.append(psi0[:,2].ravel())\n",
    "    out = (np.vstack(c_list), np.vstack(H_list), np.vstack(e0_list), np.vstack(psi0_list))\n",
    "    if not just_ground:\n",
    "        extras = (np.vstack(e1_list), np.vstack(psi1_list), np.vstack(e2_list), np.vstack(psi2_list))\n",
    "    out = out if just_ground else out + extras\n",
    "    return out\n",
    "\n",
    "def rand_psi(D_side):\n",
    "    psi = np.random.rand(1, D_side)\n",
    "    psi /= np.sqrt(np.dot(psi, psi.T))\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1217415  -1.76289773  0.57903444 -0.34138236  1.08953266 -0.07052342\n",
      "   1.06816039  0.34325798 -0.05333725  0.11313082 -1.47297761  0.00602933\n",
      "   1.71604032  1.30819356 -0.49251179  0.25284293  0.24797988  0.81718828\n",
      "   0.09415289 -0.23350399  0.66531539  0.10819828  1.25546432  0.9743862 ]] (1, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAFwCAYAAAAv9RSyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109e1b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot data\n",
    "f1 = plt.figure(figsize=[12,6])\n",
    "\n",
    "f1.text(0.5, .92, 'Example training Hamiltonians', ha='center', va='center', fontsize=18)\n",
    "v = 2\n",
    "h = 4\n",
    "c, H, e0, psi0 = next_batch(D_side, batch_size=batch_size)\n",
    "sd, mn = np.std(H), np.mean(H)\n",
    "cl = [mn-3*sd,mn+3*sd]\n",
    "\n",
    "for i in range(v):\n",
    "    for j in range(h):\n",
    "        plot_ix = i*h + j\n",
    "        curr_plot = v*100 + h*10 + plot_ix+1\n",
    "\n",
    "        plt.subplot(curr_plot)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        c, H, e0, psi0 = next_batch(D_side, batch_size=1)\n",
    "        im = plt.imshow(np.reshape(H,[D_side,D_side]))\n",
    "        plt.clim(*cl)\n",
    "        \n",
    "cax = f1.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "cb = f1.colorbar(im, cax=cax, orientation='vertical')\n",
    "cb.set_label('color scale')\n",
    "print(c, c.shape)\n",
    "    \n",
    "plt.show() #; f1.savefig('./figures/tph-training-psi0.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a neural network with three hidden layers\n",
    "def dot_norm(u):\n",
    "    m, n = u.size()\n",
    "    d = u.mm(u.t())\n",
    "    div_by = torch.sqrt(torch.diag(d))\n",
    "    v = u / div_by.resize(m, 1).repeat(1,n)\n",
    "    return v\n",
    "\n",
    "class SimpleNN3(torch.nn.Module):\n",
    "    def __init__(self, batch_size, input_dim, h_dim, output_dim):\n",
    "        super(SimpleNN3, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.W1 = nn.Parameter(torch.randn(input_dim, h_dim)*0.075)\n",
    "        self.b1 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W2 = nn.Parameter(torch.randn(h_dim, h_dim)*0.075)\n",
    "        self.b2 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W3 = nn.Parameter(torch.randn(h_dim, output_dim)*0.075)\n",
    "        self.b3 = nn.Parameter(torch.randn(output_dim)*0.075)\n",
    "        self.arch = 'SimpleNN3'\n",
    "\n",
    "    def forward(self, X, batch_size):\n",
    "        X = X.resize(batch_size, self.input_dim)\n",
    "        h1 = F.relu(X.mm(self.W1) + self.b1.repeat(X.size(0), 1))\n",
    "        h2 = F.relu(h1.mm(self.W2) + self.b2.repeat(X.size(0), 1))\n",
    "        h3 = h2.mm(self.W3) + self.b3.repeat(X.size(0), 1)\n",
    "        h3 = dot_norm(h3)\n",
    "        return h3\n",
    "    \n",
    "model = SimpleNN3(batch_size=1, input_dim=N*num_couplings, h_dim=D_hidden, output_dim=D_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global_step = 0\n",
    "# load_was_success = True # yes, I'm being optimistic\n",
    "# model_zoo = []\n",
    "# paths = glob.glob(save_dir + '/*.tar')\n",
    "# try:\n",
    "#     for s in paths:\n",
    "#         checkpoint = torch.load(s)\n",
    "#         model.load_state_dict(checkpoint['state_dict'])\n",
    "#         global_step = checkpoint['global_step']\n",
    "#         model_zoo.append((global_step, copy.deepcopy(model)))\n",
    "#         print(\"loaded model: {}\".format(s))\n",
    "#     model_zoo = sorted(model_zoo, key=lambda tup: tup[0])\n",
    "#     global_step, model = model_zoo[-1]\n",
    "# except:\n",
    "#     print(\"no saved model to load.\") ; model_zoo = []\n",
    "#     load_was_success = False\n",
    "# else:\n",
    "#     if len(paths) is 0: print(\"no saved model to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model to estimate ground state energies\n",
    "Takes ~30 min to train on my MacBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def energy_func(psi, H, batch_size):\n",
    "    psi = psi.resize(batch_size,1,D_side)\n",
    "    H = H.resize(batch_size,D_side,D_side)\n",
    "    e0_hat = psi.bmm(H).bmm(torch.transpose(psi, 2,1))\n",
    "    return e0_hat\n",
    "\n",
    "def cost_func(e, psi, H, batch_size):\n",
    "    e = e.resize(batch_size,1,1)\n",
    "    e0_hat = energy_func(psi, H, batch_size)\n",
    "    return .5*torch.sum((e0_hat-e)**2) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss: 7.7854\n",
      "\tstep 1: saved model\n",
      "\tstep 10: saved model\n",
      "\tstep 30: saved model\n",
      "step 100: loss: 8.1071\n",
      "\tstep 100: saved model\n",
      "step 200: loss: 8.2023\n",
      "\tstep 250: saved model\n",
      "step 300: loss: 8.5058\n",
      "\tstep 300: saved model\n",
      "step 400: loss: 7.3299\n",
      "step 500: loss: 7.0932\n",
      "\tstep 500: saved model\n",
      "step 600: loss: 6.7342\n",
      "step 700: loss: 6.4779\n",
      "step 800: loss: 5.9602\n",
      "step 900: loss: 6.0959\n",
      "step 1000: loss: 5.3226\n",
      "\tstep 1000: saved model\n",
      "step 1100: loss: 5.0559\n",
      "step 1200: loss: 4.8902\n",
      "step 1300: loss: 4.7995\n",
      "step 1400: loss: 4.4576\n",
      "step 1500: loss: 3.9485\n",
      "step 1600: loss: 3.9215\n",
      "step 1700: loss: 3.6642\n",
      "step 1800: loss: 3.6405\n",
      "step 1900: loss: 3.3704\n",
      "step 2000: loss: 3.5287\n",
      "\tstep 2000: saved model\n",
      "step 2100: loss: 3.7808\n",
      "step 2200: loss: 3.6953\n",
      "step 2300: loss: 3.5259\n",
      "step 2400: loss: 3.4239\n",
      "step 2500: loss: 3.3496\n",
      "step 2600: loss: 3.3420\n",
      "step 2700: loss: 3.0312\n",
      "step 2800: loss: 2.9819\n",
      "step 2900: loss: 3.0940\n",
      "step 3000: loss: 2.9975\n",
      "\tstep 3000: saved model\n",
      "step 3100: loss: 2.7997\n",
      "step 3200: loss: 2.8454\n",
      "step 3300: loss: 2.7770\n",
      "step 3400: loss: 2.9473\n",
      "step 3500: loss: 2.8394\n",
      "step 3600: loss: 2.7523\n",
      "step 3700: loss: 2.8745\n",
      "step 3800: loss: 2.7532\n",
      "step 3900: loss: 2.7675\n",
      "step 4000: loss: 2.6104\n",
      "\tstep 4000: saved model\n",
      "step 4100: loss: 2.5778\n",
      "step 4200: loss: 2.6745\n",
      "step 4300: loss: 2.6368\n",
      "step 4400: loss: 2.7625\n",
      "step 4500: loss: 2.3554\n",
      "step 4600: loss: 2.2608\n",
      "step 4700: loss: 2.2716\n",
      "step 4800: loss: 2.2438\n",
      "step 4900: loss: 2.2387\n",
      "step 5000: loss: 2.0063\n",
      "step 5100: loss: 2.1127\n",
      "step 5200: loss: 2.2275\n",
      "step 5300: loss: 2.1452\n",
      "step 5400: loss: 2.0414\n",
      "step 5500: loss: 2.1831\n",
      "step 5600: loss: 2.2737\n",
      "step 5700: loss: 2.1235\n",
      "step 5800: loss: 1.9124\n",
      "step 5900: loss: 2.0256\n",
      "step 6000: loss: 2.0532\n",
      "step 6100: loss: 1.9379\n",
      "step 6200: loss: 1.9978\n",
      "step 6300: loss: 1.9835\n",
      "step 6400: loss: 1.9126\n",
      "step 6500: loss: 1.8102\n",
      "step 6600: loss: 1.8726\n",
      "step 6700: loss: 1.7889\n",
      "step 6800: loss: 1.8323\n",
      "step 6900: loss: 1.7627\n",
      "step 7000: loss: 1.8463\n",
      "step 7100: loss: 1.7410\n",
      "step 7200: loss: 1.8127\n",
      "step 7300: loss: 1.7074\n",
      "step 7400: loss: 1.6100\n",
      "step 7500: loss: 1.6801\n",
      "step 7600: loss: 1.7133\n",
      "step 7700: loss: 1.5669\n",
      "step 7800: loss: 1.5269\n",
      "step 7900: loss: 1.6342\n",
      "step 8000: loss: 1.6644\n",
      "step 8100: loss: 1.6140\n",
      "step 8200: loss: 1.5021\n",
      "step 8300: loss: 1.6072\n",
      "step 8400: loss: 1.5322\n",
      "step 8500: loss: 1.5803\n",
      "step 8600: loss: 1.5113\n",
      "step 8700: loss: 1.4634\n",
      "step 8800: loss: 1.3856\n",
      "step 8900: loss: 1.4163\n",
      "step 9000: loss: 1.3686\n",
      "step 9100: loss: 1.3618\n",
      "step 9200: loss: 1.4327\n",
      "step 9300: loss: 1.4596\n",
      "step 9400: loss: 1.4089\n",
      "step 9500: loss: 1.4281\n",
      "step 9600: loss: 1.3758\n",
      "step 9700: loss: 1.2571\n",
      "step 9800: loss: 1.3207\n",
      "step 9900: loss: 1.4484\n",
      "step 10000: loss: 1.4268\n",
      "\tstep 10000: saved model\n",
      "step 10100: loss: 1.3260\n",
      "step 10200: loss: 1.4518\n",
      "step 10300: loss: 1.4065\n",
      "step 10400: loss: 1.3642\n",
      "step 10500: loss: 1.3755\n",
      "step 10600: loss: 1.2217\n",
      "step 10700: loss: 1.2047\n",
      "step 10800: loss: 1.1067\n",
      "step 10900: loss: 1.2000\n",
      "step 11000: loss: 1.2352\n",
      "step 11100: loss: 1.2659\n",
      "step 11200: loss: 1.2080\n",
      "step 11300: loss: 1.2471\n",
      "step 11400: loss: 1.2450\n",
      "step 11500: loss: 1.1285\n",
      "step 11600: loss: 1.2178\n",
      "step 11700: loss: 1.2607\n",
      "step 11800: loss: 1.2784\n",
      "step 11900: loss: 1.1146\n",
      "step 12000: loss: 1.1746\n",
      "step 12100: loss: 1.2223\n",
      "step 12200: loss: 1.1929\n",
      "step 12300: loss: 1.3640\n",
      "step 12400: loss: 1.2338\n",
      "step 12500: loss: 1.1252\n",
      "step 12600: loss: 1.1147\n",
      "step 12700: loss: 1.2058\n",
      "step 12800: loss: 1.1855\n",
      "step 12900: loss: 1.1393\n",
      "step 13000: loss: 1.0823\n",
      "step 13100: loss: 1.0453\n",
      "step 13200: loss: 1.1245\n",
      "step 13300: loss: 1.1371\n",
      "step 13400: loss: 1.0541\n",
      "step 13500: loss: 1.0420\n",
      "step 13600: loss: 1.0922\n",
      "step 13700: loss: 1.0369\n",
      "step 13800: loss: 1.1375\n",
      "step 13900: loss: 1.0520\n",
      "step 14000: loss: 1.0286\n",
      "step 14100: loss: 1.0503\n",
      "step 14200: loss: 1.1390\n",
      "step 14300: loss: 1.0737\n",
      "step 14400: loss: 1.0416\n",
      "step 14500: loss: 1.0104\n",
      "step 14600: loss: 1.0898\n",
      "step 14700: loss: 1.0862\n",
      "step 14800: loss: 1.0356\n",
      "step 14900: loss: 1.0241\n",
      "step 15000: loss: 1.0308\n",
      "step 15100: loss: 1.0633\n",
      "step 15200: loss: 1.0240\n",
      "step 15300: loss: 1.0904\n",
      "step 15400: loss: 1.1002\n",
      "step 15500: loss: 1.0186\n",
      "step 15600: loss: 0.9385\n",
      "step 15700: loss: 0.9778\n",
      "step 15800: loss: 0.9106\n",
      "step 15900: loss: 0.8797\n",
      "step 16000: loss: 0.9097\n",
      "\tstep 16000: saved model\n",
      "step 16100: loss: 0.9695\n",
      "step 16200: loss: 1.0665\n",
      "step 16300: loss: 1.0295\n",
      "step 16400: loss: 1.0327\n",
      "step 16500: loss: 0.9918\n",
      "step 16600: loss: 1.0079\n",
      "step 16700: loss: 0.9611\n",
      "step 16800: loss: 0.8864\n",
      "step 16900: loss: 0.8976\n",
      "step 17000: loss: 0.9123\n",
      "step 17100: loss: 0.9192\n",
      "step 17200: loss: 0.9355\n",
      "step 17300: loss: 0.9389\n",
      "step 17400: loss: 0.8987\n",
      "step 17500: loss: 0.8350\n",
      "step 17600: loss: 0.8860\n",
      "step 17700: loss: 0.8366\n",
      "step 17800: loss: 0.8487\n",
      "step 17900: loss: 0.9085\n",
      "step 18000: loss: 0.8609\n",
      "step 18100: loss: 0.8297\n",
      "step 18200: loss: 0.8097\n",
      "step 18300: loss: 0.7884\n",
      "step 18400: loss: 0.8623\n",
      "step 18500: loss: 0.8753\n",
      "step 18600: loss: 1.0347\n",
      "step 18700: loss: 0.8813\n",
      "step 18800: loss: 0.8530\n",
      "step 18900: loss: 0.8632\n",
      "step 19000: loss: 0.7952\n",
      "step 19100: loss: 0.8967\n",
      "step 19200: loss: 0.8465\n",
      "step 19300: loss: 0.8547\n",
      "step 19400: loss: 0.8057\n",
      "step 19500: loss: 0.9152\n",
      "step 19600: loss: 0.9393\n",
      "step 19700: loss: 0.9496\n",
      "step 19800: loss: 0.9465\n",
      "step 19900: loss: 0.8754\n",
      "step 20000: loss: 0.7840\n",
      "step 20100: loss: 0.9258\n",
      "step 20200: loss: 0.8434\n",
      "step 20300: loss: 0.7828\n",
      "step 20400: loss: 0.8391\n",
      "step 20500: loss: 0.7989\n",
      "step 20600: loss: 0.8262\n",
      "step 20700: loss: 0.8305\n",
      "step 20800: loss: 0.8106\n",
      "step 20900: loss: 0.7813\n",
      "step 21000: loss: 0.7853\n",
      "step 21100: loss: 0.8343\n",
      "step 21200: loss: 0.7813\n",
      "step 21300: loss: 0.8306\n",
      "step 21400: loss: 0.7539\n",
      "step 21500: loss: 0.6938\n",
      "step 21600: loss: 0.7110\n",
      "step 21700: loss: 0.6511\n",
      "step 21800: loss: 0.6384\n",
      "step 21900: loss: 0.6542\n",
      "step 22000: loss: 0.7163\n",
      "step 22100: loss: 0.7523\n",
      "step 22200: loss: 0.7266\n",
      "step 22300: loss: 0.7644\n",
      "step 22400: loss: 0.8277\n",
      "step 22500: loss: 0.8069\n",
      "step 22600: loss: 0.7292\n",
      "step 22700: loss: 0.7830\n",
      "step 22800: loss: 0.7754\n",
      "step 22900: loss: 0.7744\n",
      "step 23000: loss: 0.7279\n",
      "step 23100: loss: 0.7537\n",
      "step 23200: loss: 0.7801\n",
      "step 23300: loss: 0.7573\n",
      "step 23400: loss: 0.7553\n",
      "step 23500: loss: 0.8055\n",
      "step 23600: loss: 0.7406\n",
      "step 23700: loss: 0.7232\n",
      "step 23800: loss: 0.7888\n",
      "step 23900: loss: 0.7424\n",
      "step 24000: loss: 0.7240\n",
      "step 24100: loss: 0.6885\n",
      "step 24200: loss: 0.7224\n",
      "step 24300: loss: 0.6943\n",
      "step 24400: loss: 0.7344\n",
      "step 24500: loss: 0.7319\n",
      "step 24600: loss: 0.7346\n",
      "step 24700: loss: 0.7230\n",
      "step 24800: loss: 0.7351\n",
      "step 24900: loss: 0.7164\n",
      "step 25000: loss: 0.7095\n",
      "step 25100: loss: 0.6760\n",
      "step 25200: loss: 0.7167\n",
      "step 25300: loss: 0.6995\n",
      "step 25400: loss: 0.7053\n",
      "step 25500: loss: 0.7493\n",
      "step 25600: loss: 0.6846\n",
      "step 25700: loss: 0.6986\n",
      "step 25800: loss: 0.6670\n",
      "step 25900: loss: 0.7043\n",
      "step 26000: loss: 0.6174\n",
      "step 26100: loss: 0.6836\n",
      "step 26200: loss: 0.6164\n",
      "step 26300: loss: 0.6356\n",
      "step 26400: loss: 0.6489\n",
      "step 26500: loss: 0.6535\n",
      "step 26600: loss: 0.6853\n",
      "step 26700: loss: 0.6727\n",
      "step 26800: loss: 0.6321\n",
      "step 26900: loss: 0.6429\n",
      "step 27000: loss: 0.6543\n",
      "step 27100: loss: 0.7076\n",
      "step 27200: loss: 0.7089\n",
      "step 27300: loss: 0.6397\n",
      "step 27400: loss: 0.6267\n",
      "step 27500: loss: 0.6467\n",
      "step 27600: loss: 0.6685\n",
      "step 27700: loss: 0.7377\n",
      "step 27800: loss: 0.6853\n",
      "step 27900: loss: 0.6549\n",
      "step 28000: loss: 0.5757\n",
      "step 28100: loss: 0.6037\n",
      "step 28200: loss: 0.6682\n",
      "step 28300: loss: 0.6588\n",
      "step 28400: loss: 0.6810\n",
      "step 28500: loss: 0.6754\n",
      "step 28600: loss: 0.6857\n",
      "step 28700: loss: 0.6429\n",
      "step 28800: loss: 0.6373\n",
      "step 28900: loss: 0.6749\n",
      "step 29000: loss: 0.5874\n",
      "step 29100: loss: 0.5852\n",
      "step 29200: loss: 0.5762\n",
      "step 29300: loss: 0.5955\n",
      "step 29400: loss: 0.5687\n",
      "step 29500: loss: 0.6780\n",
      "step 29600: loss: 0.6185\n",
      "step 29700: loss: 0.6637\n",
      "step 29800: loss: 0.6296\n",
      "step 29900: loss: 0.6158\n",
      "step 30000: loss: 0.6281\n",
      "\tstep 30000: saved model\n",
      "step 30100: loss: 0.6572\n",
      "step 30200: loss: 0.6842\n",
      "step 30300: loss: 0.6307\n",
      "step 30400: loss: 0.6921\n",
      "step 30500: loss: 0.6321\n",
      "step 30600: loss: 0.6015\n",
      "step 30700: loss: 0.6130\n",
      "step 30800: loss: 0.5954\n",
      "step 30900: loss: 0.6081\n",
      "step 31000: loss: 0.5687\n",
      "step 31100: loss: 0.5877\n",
      "step 31200: loss: 0.6523\n",
      "step 31300: loss: 0.6785\n",
      "step 31400: loss: 0.6584\n",
      "step 31500: loss: 0.5685\n",
      "step 31600: loss: 0.5913\n",
      "step 31700: loss: 0.5394\n",
      "step 31800: loss: 0.5888\n",
      "step 31900: loss: 0.6140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32000: loss: 0.6311\n",
      "step 32100: loss: 0.5894\n",
      "step 32200: loss: 0.5933\n",
      "step 32300: loss: 0.5583\n",
      "step 32400: loss: 0.5384\n",
      "step 32500: loss: 0.6180\n",
      "step 32600: loss: 0.5465\n",
      "step 32700: loss: 0.6026\n",
      "step 32800: loss: 0.5671\n",
      "step 32900: loss: 0.5791\n",
      "step 33000: loss: 0.5669\n",
      "step 33100: loss: 0.5887\n",
      "step 33200: loss: 0.5860\n",
      "step 33300: loss: 0.6052\n",
      "step 33400: loss: 0.6078\n",
      "step 33500: loss: 0.5710\n",
      "step 33600: loss: 0.5827\n",
      "step 33700: loss: 0.6219\n",
      "step 33800: loss: 0.6113\n",
      "step 33900: loss: 0.5833\n",
      "step 34000: loss: 0.5641\n",
      "step 34100: loss: 0.5350\n",
      "step 34200: loss: 0.5837\n",
      "step 34300: loss: 0.5682\n",
      "step 34400: loss: 0.5889\n",
      "step 34500: loss: 0.6114\n",
      "step 34600: loss: 0.6285\n",
      "step 34700: loss: 0.6452\n",
      "step 34800: loss: 0.5816\n",
      "step 34900: loss: 0.6108\n",
      "step 35000: loss: 0.5614\n",
      "step 35100: loss: 0.5716\n",
      "step 35200: loss: 0.5713\n",
      "step 35300: loss: 0.5465\n",
      "step 35400: loss: 0.5912\n",
      "step 35500: loss: 0.5482\n",
      "step 35600: loss: 0.6066\n",
      "step 35700: loss: 0.6177\n",
      "step 35800: loss: 0.6156\n",
      "step 35900: loss: 0.5809\n",
      "step 36000: loss: 0.5781\n",
      "step 36100: loss: 0.5647\n",
      "step 36200: loss: 0.5874\n",
      "step 36300: loss: 0.5772\n",
      "step 36400: loss: 0.5827\n",
      "step 36500: loss: 0.5475\n",
      "step 36600: loss: 0.5235\n",
      "step 36700: loss: 0.5721\n",
      "step 36800: loss: 0.6007\n",
      "step 36900: loss: 0.6001\n",
      "step 37000: loss: 0.5309\n",
      "step 37100: loss: 0.5383\n",
      "step 37200: loss: 0.5571\n",
      "step 37300: loss: 0.5665\n",
      "step 37400: loss: 0.6025\n",
      "step 37500: loss: 0.5286\n",
      "step 37600: loss: 0.5517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c732641c4160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# ======== DISCRIMINATOR STEP ======== #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnp_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_e0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_psi0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_side\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mreal_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mreal_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ac3b90190c0a>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(D, batch_size, just_ground)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0me1_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mpsi1_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0me2_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mpsi2_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mham\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0me0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigsh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mH_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0me0_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mpsi0_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsi0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ac3b90190c0a>\u001b[0m in \u001b[0;36mham\u001b[0;34m(J, Jz, rand)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFreeSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menlarge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_couplings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c35291bf3e8d>\u001b[0m in \u001b[0;36menlarge\u001b[0;34m(self, site)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menlarged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'H'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_H\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sxz'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c35291bf3e8d>\u001b[0m in \u001b[0;36minteraction_H\u001b[0;34m(self, site)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mSxz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sxz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# other block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mjoin_Sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'J'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mjoin_Sxz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Jz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSxz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSxz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjoin_Sp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjoin_Sxz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# self + other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# other + self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inconsistent shapes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_plus_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Convert this matrix to a dense matrix and add them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_binopt\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;34m\"\"\"apply the binary operation fn to two sparse matrices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;31m# e.g. csr_plus_csr, csr_minus_csr, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    337\u001b[0m                       indptr, indices, data)\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                     \u001b[0midx_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mget_index_dtype\u001b[0;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mint32max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaxval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mint32max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "running_loss = None\n",
    "model_zoo = []\n",
    "# generic train loop\n",
    "for global_step in range(global_step, total_steps+global_step+1):\n",
    "    \n",
    "    # ======== DISCRIMINATOR STEP ======== #\n",
    "    # forward\n",
    "    np_c, np_H, np_e0, np_psi0 = next_batch(D_side, batch_size)\n",
    "    real_c = Variable(torch.Tensor(np_c))\n",
    "    real_H = Variable(torch.Tensor(np_H))\n",
    "    real_e0 = Variable(torch.Tensor(np_e0))\n",
    "    real_psi0 = Variable(torch.Tensor(np_psi0))\n",
    "    \n",
    "    psi0_hat = model(real_c, batch_size) \n",
    "\n",
    "    # backward\n",
    "    loss = cost_func(real_e0, psi0_hat, real_H, batch_size)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    running_loss = loss.data.numpy()[0] if running_loss is None else .99*running_loss + (1-.99)*loss.data.numpy()[0]\n",
    "\n",
    "    # ======== DISPLAY PROGRESS ======== #\n",
    "    if global_step % print_every == 0:\n",
    "        print('step {}: loss: {:.4f}'.format(global_step, running_loss))\n",
    "    if global_step in checkpoint_steps:\n",
    "        print('\\tstep {}: saved model'.format(global_step))\n",
    "        torch.save({'state_dict': model.state_dict(),\n",
    "                   'global_step': global_step}\n",
    "                   , save_dir + '/model.{}.tar'.format(global_step))\n",
    "# mean loss of an untrained model is ~21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model: couplings2psi0-models/model.1.tar\n",
      "loaded model: couplings2psi0-models/model.10.tar\n",
      "loaded model: couplings2psi0-models/model.100.tar\n",
      "loaded model: couplings2psi0-models/model.1000.tar\n",
      "loaded model: couplings2psi0-models/model.10000.tar\n",
      "loaded model: couplings2psi0-models/model.16000.tar\n",
      "loaded model: couplings2psi0-models/model.2000.tar\n",
      "loaded model: couplings2psi0-models/model.250.tar\n",
      "loaded model: couplings2psi0-models/model.30.tar\n",
      "loaded model: couplings2psi0-models/model.300.tar\n",
      "loaded model: couplings2psi0-models/model.3000.tar\n",
      "loaded model: couplings2psi0-models/model.30000.tar\n",
      "loaded model: couplings2psi0-models/model.37672.tar\n",
      "loaded model: couplings2psi0-models/model.4000.tar\n",
      "loaded model: couplings2psi0-models/model.500.tar\n",
      "using model from step 37672\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "load_was_success = True # yes, I'm being optimistic\n",
    "model_zoo = []\n",
    "paths = glob.glob(save_dir + '/*.tar')\n",
    "\n",
    "try:\n",
    "    for s in paths:\n",
    "        checkpoint = torch.load(s)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        global_step = checkpoint['global_step']\n",
    "        model_zoo.append((global_step, copy.deepcopy(model)))\n",
    "        print(\"loaded model: {}\".format(s))\n",
    "    model_zoo = sorted(model_zoo, key=lambda tup: tup[0])\n",
    "    global_step, model = model_zoo[-1]\n",
    "    print(\"using model from step {}\".format(global_step))\n",
    "except:\n",
    "    print(\"no saved model to load.\") ; model_zoo = []\n",
    "    load_was_success = False\n",
    "else:\n",
    "    if len(paths) is 0: print(\"no saved model to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51176077965646982, 0.4870136296376586]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAACsCAYAAAB8QXjYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmUXVWd9vHvk4QwRZkCCAkSFBoE1IBIo7aKAk1AJdqo\nDU6guOy2pR3AAcT2bdGlwW6nVl81zA2IKEgbFEEGEV9b0TCFSWSGhDEgs5ChnvePcwovlarUqbqn\n7vh81jqr7jl3n7P3rqrc/GqPsk1EREREv5nU7gJEREREtEOCoIiIiOhLCYIiIiKiLyUIioiIiL6U\nICgiIiL6UoKgiIiI6EsJgiIiIqIvJQiKiIiIvpQgKCIiIvrSlHYXICIiItpn79et6wcfWlkp7eWL\nnj7f9pwJLlLLJAiKiIjoY0sfWsll58+slHaNzW6ZPsHFaal0h0XEqCTdLmnPdpcjIupnzHKvrHT0\nmrQERURE9LkBBtpdhLZIS1BEF5K0uaSzJD0g6TZJHy6vv1DSQ5J2bkj3gKTdy/MjJN0i6TFJ10t6\nS8Mzt5D04zL9g5K+VV4/BXg+cI6kxyV9cpjyfFXSMeXrKyTtJWkjSSskrTXh35CIGLeiJWig0tFr\nEgRFdBlJk4BzgKuBGcAewEcl7W37FuBTwKmS1gFOBE62fUl5+y3Aq4H1gM+V6TaTNBn4KXAHMKt8\n7g8AbL8buBN4k+1ptr88TLFeDCwqn/Mi4Jry2k22n6r5WxARNTKwnIFKR69JEBTRfV4ObGz7aNvL\nbN8KHAscAGD7WOBm4DJgM+CowRtt/8j23bYHbJ8B3ATsWh6bA5+w/YTtp2z/vzGU6cUUgc82wOO2\n7y2vLQKQdIykX0s6RdIazVU/IupkYKVd6eg1CYIius+WwOaSHh48gE8DmzakORbYEfim7acHL0p6\nj6SrGu7bEZgObAHcYXvFWAsjaTqwEfBH/hoMwV9bh14KzLD96jLNW8eaR0RMHGOWVzx6TYKgiO5z\nF3Cb7fUbjufY3hdA0jTg68DxwL9L2rC8viVFcHQosJHt9YFrAZXPfL6kkSZLrO7T7wXAYtvLKAKf\na8vruwG/A14J/KK8dh7wqvFUOiImhg3LKx69JkFQRPf5PfCYpE9JWlvSZEk7Snp5+f43gIW23w/8\nDPhueX1dimDmAQBJ76VoCRp85j3APEnrSlpLUmOwch9FsDMcAxuUwdeOwDWS9qVoHboU2AB4tEz7\nCLBhM5WPiHoZsdzVjl6TICiiy9heCbwRmA3cBiwFjgPWkzQXmAN8sEx+GLCzpHfavh74CvBbiqDm\nxcBvGp75JmBrikHQi4F/bMj2S8Bnym60jw8p0kKKsT/XAq+jaGn6NrC/7eXAw8Bzy7TrAQ/V8G2I\niBqtRJWOKiTNkXSjpJslHbGadPtLsqRdaqvIGMk9ONApIlqr7EbbB/gJ8Abgl4OzwiTNBg6z/R5J\nn6boyju9faWNiEY7vGSqv//TTUdPCMzecvHltkcMWsoZon8C9qL4Y+oPwIHlH2GN6Z5D0VI9FTjU\n9sJxFr8paQmKiKaVA6rvBW61/fPGafG2rwLuk/RrYAfgrDYVMyKGMYBYxuRKRwW7AjfbvrUcJ/gD\nYO4w6T4PHAO0dQmNplaMLgdcnkGxrsjtwNtt/3mYdCv564yRO23v10y+EdGRnpkSP5TtT7S4LBEx\nBgPVx/tMl9TYajPf9vyG8xkUEy0GLQb+tvEB5WKuW9j+maS2fjY0u23GEcBFtueV/X5HUCzUNtRf\nbM9uMq+I6GC2TwBOaHc5ImJsjFjmSq08AEtX1x02mnKx168CB4/3GXVqtjtsLnBy+fpk4M1NPi8i\nIiJaqFgxenKlo4IlFOuODZpZXhv0HIpZpJdIup1iKY0F7Roc3WwQtKnte8rX9/LsxdoarSVpoaTf\nSUqgFBER0SFssdKTKh0V/AHYRtJWkqZSrGS/4K95+RHb023Psj2LYi2x/do1MHrU7jBJFwLPG+at\noxpPbFvSSFPNtrS9RNILgIslXVPucTQ0rw8AHwCYvNaUl03bcoNRK1CXZQ+u2bK8AKY8ubKl+U19\n/rKW5rdsoHLTai1WPDy1pfm1cgudgee2dr+emeusMqxvQt13R2uXDdJjT7Y0vw12WN7S/O59fL2W\n5sdAi9eOmdLafw9a1tr5Q08vWbzU9satzHOwJaiWZ9krJB0KnA9MBk6wfZ2koynWL1uw+ie01qhB\nkO09R3pP0n2SNrN9j6TNgPtHeMaS8uutki4BdqLYyHFouvnAfID1t9vEux/XutX17zh165blBbDx\n5Y+OnqhGm337zpbmt/iJ9Vua39Kztxg9UY0mP9W6pSWe2PvxluUFcMzs1k7e+voHD2xpfmtceHlL\n89v/rGE/FifMl36zb0vzm/RYs0NLx0abtnYy0aTb125pfrccefgdLc2QwcUS6/s52j4XOHfItc+O\nkHb32jIeh2ZD3AXAQeXrgyjWCHkWSRtIWrN8PZ1iyfzrh6aLiIiI1hscGF3l6DXNBkHzgL0k3QTs\nWZ4jaRdJx5VpXgQslHQ18Etg3tBFkyIiIqJ9Bjyp0tFrmmr/sv0gsMcw1xcC7y9f/y/F+iERERHR\nYQbGNkW+p7S2MzciIiI6SrGLfH+GA/1Z64iIiCiJgYqbo/aaBEERERF9zMCytARFREREvymmyGdM\nUERERPQZQ0/O/KqillpLmiPpRkk3lxupDn1/TUlnlO9fJmlWHflGREREcwZbgqocvabpIEjSZODb\nwD7A9sCBkrYfkuwQ4M+2twa+BhzTbL4RERHRPDtBUDN2BW62favtZcAPKHaXb9S42/yZwB6S+nMo\nekRERIepcQPVrlLHmKAZwF0N54uBvx0pTbm52iPARsDSGvKPiIiIccrA6A7RuIv82ptOa3NpIiIi\nep8hQVATlgCNW3jPLK8Nl2axpCnAesCDQx80dBf5GsoWERERq2HEij4Nguro4PsDsI2krSRNBQ6g\n2F2+UeNu828FLradICciIqLNbFhpVTp6TdMtQeUYn0OB84HJwAm2r5N0NLDQ9gLgeOAUSTcDD1EE\nShEREdFmRqwY6M+WoFrGBNk+Fzh3yLXPNrx+CnhbHXlFREREfYoxQb0386uKjhoYHREREa2mvl0x\nOkFQREREH7PTEhQRERF9KGOCIiIiom8N0Hszv6roz/aviIiIAIqB0SsGJlc6qqiwqfphkq6XtEjS\nRZK2rLtOVbVqF/mDJT0g6aryeH8d+UZERERzbLHCkyodo6m4qfqVwC62X0Kxn+iXa65SZU13hzVU\neC+KfcP+IGmB7euHJD3D9qHN5hcRERH1GqhvIcRnNlUHkDS4qfozMYHtXzak/x3wrroyH6s6xgSN\nWuGIiIjoTEV3WG2jY6psqt7oEODndWU+Vq3aRR5gf0mvAf4EfMz2XcOkiYiIiBYq9g6rHARNl7Sw\n4Xx+ue/nmEl6F7AL8Nrx3F+HVs0OOwc43fbTkv4JOBl4/dBEjbvIA4//5NXfuXEceU0Hlo67pJ1v\nfPVbXRzeWfLzG+rYiSnISN7S3O3j+Pktai7H1hnX7+aF201ASVbr0vHemH97naHlg4TtMbUELbW9\ny2rer7KpOpL2BI4CXmv76aqZ160lu8jbbtwx/jhGGATVuIv8eElaOMoPqKulft0t9etevVw3SP36\nXY1jgp7ZVJ0iFjgAeEdjAkk7Ad8D5ti+v66Mx6Mlu8hL2qzhdD/ghhryjYiIiCYZsXJgUqVj1GfZ\nK4DBTdVvAH44uKm6pP3KZP8BTAN+VM4YXzDC4yZcq3aR/3BZ+RUUu8gf3Gy+ERER0TybsYwJqvC8\nUTdV37O2zJrUql3kjwSOrCOvCprqTusCqV93S/26Vy/XDVK/vub6usO6imy3uwwRERHRJtP+ZjPv\n+M2DK6W9bM68y3tpbFW2zYiIiOhjNqwcUKWj00j6m3LrjWvL85dI+kzV+3sqCBpt+45uJmkLSb8s\n91u5TtJH2l2mukmaLOlKST9td1nqJml9SWdK+qOkGyS9ot1lqpOkj5W/l9dKOl3SWu0uUzMknSDp\n/sEP1vLahpIukHRT+XWDdpaxGSPU7z/K389Fks6WtH47y9iM4erX8N7hkixpejvK1qkGUKWjAx1L\nMdxmOYDtRRQTtCrpmSCo4n4l3WwFcLjt7YHdgA/1WP0APkLvzhz8BnCe7e2Al9JD9ZQ0A/gwxV5A\nO1JMkKj8IdShTgLmDLl2BHCR7W2Ai8rzbnUSq9bvAmDHcj+nP9G6cZwT4SRWrR+StgD+Hriz1QXq\nZHXODmuDdWz/fsi1FVVv7sgajdMz23fYXgYMbt/RE2zfY/uK8vVjFP+JzmhvqeojaSbwBop1pHqK\npPWA1wDHA9heZvvh9paqdlOAtSVNAdYB7m5zeZpi+1KKmayN5lIs9Er59c0tLVSNhquf7V+U05uh\n2M9pZssLVpMRfn4AXwM+SbFTRDQYGFClowMtlfRCyp+ppLcC91S9uZeCoOG27+iZIKGRpFnATsBl\n7S1Jrb5O8eE00O6CTICtgAeAE8vuvuMkrdvuQtXF9hLgPyn+ur4HeMT2L9pbqgmxqe3BD9d7gU3b\nWZgJ9j7auJ/TRJA0F1hi++p2l6XT2MXssCpHB/oQxcKL20laAnwU+GDVm3spCOoLkqYBZwEftf1o\nu8tTB0lvBO63fXm7yzJBpgA7A9+xvRPwBN3dlfIs5diYuRTB3ubAuuWeQD3LxbTanmxNkHQURXfC\nae0uS10krQN8GvjsaGn7VbcOjC57f/YENga2s/13tm+ven+r9g5rhUr7lXQzSWtQBECn2f5xu8tT\no1cB+0naF1gLeK6kU233yn+ki4HFtgdb7s6kh4IgYE/gNtsPAEj6MfBK4NS2lqp+90nazPY95Sr4\nbV3ufyJIOhh4I7CHe2v9lBdSBOlXS4Li/4crJO1q+962lqwDGDHQmeN9RiTpsBGuA2D7q1We0121\nXr1Rt+/oZip+sscDN1T94XYL20fanml7FsXP7eIeCoAoP2TvkrRteWkP4Po2FqludwK7SVqn/D3d\ngx4a+N1gAXBQ+fog4CdtLEvtJM2h6JLez/aT7S5PnWxfY3sT27PKz5nFwM4JgEou9g6rcnSQ54xy\nVNIzLUEjbd/R5mLV6VXAu4FrJF1VXvt0uVp3dL5/BU4rA/Rbgfe2uTy1sX2ZpDOBKyi6Ua6ky1fn\nlXQ6sDswXdJi4P8A84AfSjoEuAN4e/tK2JwR6ncksCZwQfnX9O9s/3PbCtmE4epn+/j2lqrDdVm7\nn+3P1fGcrBgdERHRx9Z64QzP/FK1scS3/OO/ddSK0eWaZIcAO1AMpwDA9vuq3N9L3WERERExRjZ4\nYFKlowOdAjwP2Bv4FcV4r8eq3tyRNYqIiIjWKabJj350oK1t/xvwhO2TKdab+9uqN/fMmKCIiIgY\nD+EOnP5e0fLy68OSdqRYw2uTqjcnCIqIiOhnppuDoPnlWmWfoZjBOY0xrAeVICgiIqLfdWZX16hs\nD261dCnwgrHenzFBERER/c6qdnQYSV+UtH7D+QaSvlD1/gRBERER/czAgKodnWefxg2pbf8Z2Lfq\nzekOi4iI6HMdOvOrismS1rT9NICktSkW/awkQVBERES/68xWnipOAy6SdGJ5/l7g5Ko3pzssIiKi\nnxk0UO2oQtIcSTdKulnSKptFS1pT0hnl+5dJmjXuotvHAF8AXlQen7f95ar3JwiKiIjoaxXHA1Vo\nLZI0Gfg2sA+wPXCgpO2HJDsE+LPtrYGvAceMu+TSusAvbH8cOBZYU9IaVe9PEBQREdHvXPEY3a7A\nzbZvtb0M+AEwd0iaufy1y+pMYA+Vu/aOw6XAWpJmAOdRbDR+UtWbEwRFRET0s3pnh80A7mo4X1xe\nGzaN7RXAI8BG4yy9bD8J/APwHdtvo9hMtZIMjI6IiOhzVcf7ANMlLWw4n297fv0lqkySXgG8k6Kb\nDWBy1ZsTBEVERERVS23vspr3lwBbNJzPLK8Nl2axpCnAesCD4yzPR4AjgbNtXyfpBcAvq96cICgi\nIqLPqb4p8n8AtpG0FUWwcwDwjiFpFgAHAb8F3gpcbI9vpSLbl1KMCxo8vxX4cNX7EwRFRET0MwPV\nu8NW/yh7haRDgfMpuqVOKFtojgYW2l4AHA+cIulm4CGKQKktEgRFRET0OdW4YrTtc4Fzh1z7bMPr\np4C31Zfj+GV2WERERL8bqHh0EEmTJX2smWckCIqIiOhjcjEmqMrRSWyvBA5s5hnpDouIiOh33buB\n6m8kfQs4A3hi8KLtK6rcnCAoIiKiz41hnaBOM7v8enTDNQOvr3JzgqCIiIh+5u4Ngmy/rpn7MyYo\nIiKiz9W5i3wrSVpP0lclLSyPr0har+r9CYIiIiKiW50APAa8vTweBU6senO6wyIiIvpZF3eHAS+0\nvX/D+eckXVX15rQERURfkrSvpH3bXY6IjtCF6wSV/iLp7wZPJL0K+EvVm9MSFBF9R9J04Avl68ts\nj3fzxoiuJ+pdMbrFPgicXI4DEsU2HAdXvTlBUET0o88Bn6TY2+ho4EPtLU5EG3Vxd5jtq4CXSnpu\nef7oWO5PEBR9R9LtwPttX9jusvQiSdcBH7J9SbvLMhLbjUHP+W0rSESn6LIgSNJhI1wHwPZXqzwn\nY4IioimSbpe05+C57R0mKgAamldE1EOudnSQ54xyVJKWoIguJWmK7RXtLkdEdDnTdS1Btj9Xx3PS\nEhR9TdKLJF0i6WFJ10nar7z+XknnNKS7SdKPGs7vkjR7hGduLuksSQ9Iuk3Sh4e8f7ukj0taJOkR\nSWdIWmsM935K0iLgCUlTJO0s6UpJj0n6Ufm8L0j6hKSzhtz/X5K+Mc5yf0rSkjKfGyXtIekU4PnA\nOZIel/TJoa015fknyvo+Iel4SZtK+nn5rAslbdCQ/ghJt5TvXS/pLeX1VfKqUu4hdfiqpGPK11dI\n2kvSRpJWDP4MIvpRFy+WOFPS2ZLuL4+zJM2sen+CoOhbktYAzgF+AWwC/CtwmqRtgV8Br5Y0SdLm\nwFTgFeV9LwCmAYuGeeak8plXAzOAPYCPStp7SNK3A3OArYCXAAeP4d4DgTcA61P8Gz4bOAnYEDgd\neEuZ7lRgjqT1y7JNAQ4A/nus5S6/J4cCL7f9HGBv4Hbb7wbuBN5ke5rtL6/yjS7sD+wF/A3wJuDn\nwKeBjcs6NAYutwCvBtajGMB8qqTNhstrDN+zQS8GFkmaDLwIuKa8dpPtp0a4J6LndWF32KATgQXA\n5uVxDmNYLDFBUPSz3SiCmXm2l9m+GPgpcKDtWylWIZ0NvIZi8OzdkrYDXgv82vZwfxe9HNjY9tHl\nM28FjqUIPhr9l+27bT9E8Y929hjvvcv2X8o6TCmvLbf9Y+D3ALbvAS4F3lbeNwdYavvycZR7JbAm\nsL2kNWzfbvuWkb+1q/im7ftsLwF+DVxm+8oy8Dgb2Gkwoe0fld+bAdtnADcBu47w3Krfs0Evpgh8\ntgEet31veW0RgKQfDmnxu0KFYa+Pof4RnWuwO6w71wna2PaJtleUx0kUf1xVkjFB0c82B+4aEszc\nQdGiAEVr0O7A1uXrhykCoFeU50h6J/C9Mv2vKf4C2VzSww3PnFy+1+jehtdPlmXZsuK9dw2pwxLb\nHuH9kynW0TgWeBdwCsNbbd62b5b0UeDfgR0knQ8cZvvuEZ431H0Nr/8yzPm0wRNJ7wEOA2aVl6YB\n08dT7kYq1gbaCPgjMJciGIKGIKh83pNlS9EawNO2LWnY66urcES36PJ1gh6U9C6KVnAoWsorr/uV\nICj62d3AFpImNQRCzwf+VL7+FUXXzVbAFymCoHdSBEHfArB9GnDa4AMlvQK4zfY24yjPXRXvbfy4\nugeYIUkN/ylvQdGlBPA/wHck7Qi8kWJtnHHlbfv7wPdVrMfxPeAY4N1DytOUMtg4lqJb67e2V6pY\nAn+w1WVoXlW/ZwAvABbbXibpxcC15fXdgDMkTQWWA7+j+Bk/Dtww0vXx1jGiE3XieJ+K3gd8E/ga\nxefD/wLvrXpzusOin11G0QrzSUlrSNqdIuj5Qfn+r4DXAWvbXkzRujCHojXhyhGe+XvgsXIQ8dqS\nJkvaUdLLK5RnPPf+lqKr6lAVg6Tn0tB1VHY3nQl8H/i97TvHk7ekbSW9XtKawFMUrTeDH5v3UQQY\ndViX4oPsgTLf9wI7Nrw/NK+xfM8MbCBpWvnMa1Rsm7ERRbfhdhQB8HkUP+cdKQKlka5H9A5XPDqM\n7Tts72d7Y9ub2H7zaj7nVpEgKPqW7WUUQc8+wFLg/wLvsf3H8v0/UfzVP9gl9ChwK/Ab2ytHeOZK\nihaX2cBt5XOPoxjkO1p5xnxvWYd/AA6haKl6F8W4pqcbkp1M0eUzUldYlbzXBOaV1++lGEh+ZPne\nl4DPqJhh9/HR6rk6tq8HvkIR3N1Xlvs3DUmeldcYv2cLKbq9rqUIbg8Fvg3sb3s5RXBzHcVfkq8E\ndijTjnQ9oje4q2eHnTw4+aM830DSCZXvT7d2RG+RdBnwXdsnlufPpxgH87yxLinfa8oZcvsAP6GY\nYffLwVlhkr4IXGr7PEk/phhv9Q8UwdIq18cwHiqio62zyRbe9q3DLsC8iqu+c9jltneZ4CJVJulK\n2zuNdm0kaQmK6HKSXivpeWV32EEUU+7PK9+bRDHI+Af9HgABlItL3gvcavvnQ6bFD7b4QLFswjZl\noDPS9Yie0Yop8pI2lHSBinXXLlDD+mANaWZL+q2KddsWSfrHUR47Sc9eZ2xDxjDeuakgqEqFynQr\nJV1VHguayTMiVrEtxTo5DwOHA2+1fY+kdYFHKdbn+T9tLF+naZwN9oxyXMFd5evv2t5oddcjekbr\npsgfAVxUTmS4qDwf6kmKYQk7UIzB+3pjd9cwvgL8VtLnJX2eott6pPXKVtFUd5ikLwMP2Z4n6Qhg\nA9ufGibd47anrfqEiIiIaKd1N97C2725WnfYFceNvztM0o3A7uUfaZsBl9jedpR7rqb4w+6m1aTZ\nHnh9eXpxObawkmanyM+lWEcFisGXlwCrBEERERHRuVS9QWS6pIUN5/Ntz69476blIq5QdEtvutoy\nSbtSrNa/2oVZy6CncuDTqNkgqGqF1iq/aSsoVuf9nybzjYiIiDp4TDO/lq6uJUjShcDzhnnrqGdl\nWSxCOmLkVbYUnQIcNMLq/LUYNQiqqUJb2l6iYs+liyVdM9yS+5I+AHwAYJ119LJttm7dWo633TTS\ngrQTZKC1cw3XfMHylub3yOPrtDS/tdZZ1tL8nnpiausym9zaGZybTGvt+OmlD4y6ekCtpj66orX5\nbdXa383H/9zaf3tu8eYhrZ6mPbBGa/NbtnjxUtuVt32oS13fV9t7jvSepPtU7AM42B12/wjpngv8\nDDjK9u/qKdnwRo0y6qhQuV8Qtm+VdAnFPkGrBEFlk9p8gNkvneqLzm3d78E73nhIy/IC0JNPj56o\nRlufetfoiWr0s1+/rKX5vWinO1qa3x//MKtlea3csLUB7Ed2u7Cl+Z04f9+W5jfjvGE/pibMrFMW\ntzS/S8/cuaX5rVyzpdkx9bHW5vfEjNZGXbcd/vHWfpgNas3fWguAgyjWHDuIYqmKZylXaD8b+G/b\nZ050gZqdIj9YIRi5QhuUq8wO7t3zKsbZdxcRERE1a91iifOAvSTdBOxZniNpF0nHlWneTrFp9cEN\ns8pnN53zCJrtb5oH/FDSIRQbT74digoB/2z7/cCLgO9JGqAIuuaNZeR2RERETBwBGpj4piDbD1Ls\nCzj0+kLg/eXrU4FTJ7wwpaaCoIoV+l+KdTkiIiKi04xtYHRPyS7yERERfS5BUERERPSlBEERERHR\nf9yaMUGdKEFQREREv+vPGChBUERERD+T3bctQc2uEwSApDmSbpR0c7mR6tD315R0Rvn+ZZJm1ZFv\nRERENK9F6wR1nKaDIEmTgW8D+wDbAweWO7o2OgT4s+2tga8BxzSbb0RERNRDrnb0mjpagnYFbrZ9\nq+1lwA8odpdvNJdil3mAM4E9JLV4x5mIiIhYhYGVrnb0mDqCoBlA48ZUi8trw6axvQJ4BNiohrwj\nIiKiSRpwpaPXdNTA6MZd5GfOmNzm0kRERPSBPl4xuo6WoCXAFg3nM8trw6aRNAVYD3hw6INsz7e9\ni+1dNtqoljHbERERsRqinCFW4eg1dUQafwC2kbSVpKnAARS7yzdq3G3+rcDFdg9+NyMiIrqQVrrS\n0Wua7g6zvULSocD5wGTgBNvXSToaWGh7AXA8cIqkm4GHKAKliIiIaDcbenC8TxW1jAmyfS5w7pBr\nn214/RTwtjryioiIiHr14vT3KjpqYHRERES0mOnJrq4qEgRFRET0u3SHRURERD/qxZlfVSQIioiI\n6GeDK0b3oQRBERERfUwYDfTnaomt2kX+YEkPSLqqPN5fR74RERFRA7va0WNatYs8wBm2Z5fHcc3m\nGxERETVwaxZLlLShpAsk3VR+3WA1aZ8rabGkbzWV6ShatYt8REREdCTDwEC1ozlHABfZ3ga4qDwf\nyeeBS5vNcDSt2kUeYH9JiySdKWmLYd6PiIiIVhscGF3laM5c4OTy9cnAm4dLJOllwKbAL5rNcDSt\nGhh9DnC67acl/RNF5V8/NFHjLvLA49Nn3n3jOPKaDiwd+22fH0dWbTGu+p3/sgkoyWqdPt4bx1W/\n28ebW+uN8/ezdQ5v7vZx1O/C5nIco2vHf+v4fna7jD/D8Tl1vDd2/O9mk7qlflu2I9MxTJGfLmlh\nw/l82/Mr3rup7XvK1/dSBDrPLoc0CfgK8C5gz6qFGq86gqBRd5G33bhj/HHAl4d7UPmNrPrNHJak\nhbZb/rHTKqlfd0v9ulcv1w1Sv75mYGXlrq6lq/s+SroQeN4wbx31rCxtS8Nu1vEvwLm2F0uqWqZx\nqyMIemYXeYrg5wDgHY0JJG3WEP3tB9xQQ74RERHRNNcx3qd4kj1i642k+wbjAUmbAfcPk+wVwKsl\n/QswDZgq6XHbqxs/NG6t2kX+w5L2A1ZQ7CJ/cLP5RkRERE1aM/19AXAQMK/8+pNVi+F3Dr6WdDCw\ny0QFQNAA1iagAAAEQUlEQVS6XeSPBI6sI68KmupO6wKpX3dL/bpXL9cNUr/+ZcPKla3IaR7wQ0mH\nAHcAbweQtAvwz7Zbvoag3IOLH0VEREQ1603d1K983oGV0p531zcu76WxVdk2IyIiot/1aYNILdtm\ndIrRtu/oZpK2kPRLSddLuk7SR9pdprpJmizpSkk/bXdZ6iZp/XKNrD9KukHSK9pdpjpJ+lj5e3mt\npNMlrdXuMjVD0gmS7pd0bcO1yqvddroR6vcf5e/nIklnS1q/nWVsxnD1a3jvcEmWNL0dZetMLVss\nseP0TBA0hu07utUK4HDb2wO7AR/qsfoBfITenTn4DeA829sBL6WH6ilpBvBhigGMO1JMkDigvaVq\n2knAnCHXxrLabac7iVXrdwGwo+2XAH+ideM4J8JJrFo/yoV6/x64s9UF6mimGBNU5egxPRME0ePb\nd9i+x/YV5evHKP4THW5l7q4kaSbwBop1pHqKpPWA1wDHA9heZvvh9paqdlOAtSVNAdYB7m5zeZpi\n+1KKmayNKq122w2Gq5/tX9heUZ7+jmLNt640ws8P4GvAJyn+249G2UC161XdvqPrSZoF7ARc1t6S\n1OrrFB9OvdfeClsBDwAnlt19x0lat92FqovtJcB/Uvx1fQ/wiO0JX+6+DUZd7baHvA/4ebsLUSdJ\nc4Eltq9ud1k6jo1Xrqx09JpeCoL6gqRpwFnAR20/2u7y1EHSG4H7bV/e7rJMkCnAzsB3bO8EPEF3\nd6U8Szk2Zi5FsLc5sK6kd7W3VBPLxbTa3vuzGJB0FEX3+2ntLktdJK0DfBr47Ghp+9bKgWpHj+ml\nIGjU7Tu6naQ1KAKg02z/uN3lqdGrgP0k3U7Rjfl6SePeAKkDLQYW2x5suTuTIijqFXsCt9l+wPZy\n4MfAK9tcpolwX7nKLatZ7barlYvTvRF4p3tr/ZQXUgTpV5efMzOBKyQNt71D/xlcJyhjgrraM9t3\nSJpKMTBzQZvLVBsVm6gcD9xg+6vtLk+dbB9pe6btWRQ/t4tt90xLgu17gbskbVte2gO4vo1Fqtud\nwG6S1il/T/eghwZ+Nxhc7RZGWO22m0maQ9ElvZ/tJ9tdnjrZvsb2JrZnlZ8zi4Gdy3+bAXhgoNLR\na3omCCoH9A1u33ED8EPb17W3VLV6FfBuilaSq8pj33YXKir7V+A0SYuA2cAX21ye2pQtXGcCVwDX\nUHyudPXqvJJOB34LbCtpcbnC7TxgL0k3UbR+zWtnGZsxQv2+BTwHuKD8fPluWwvZhBHqFyOx+7Y7\nLCtGR0RE9LHnTtrIu03Zu1LaC5afnhWjIyIiokfY4N5r5akiLUERERF9TNJ5QNUVtJfaXmUhym6V\nICgiIiL6Us8MjI6IiIgYiwRBERER0ZcSBEVERERfShAUERERfSlBUERERPSlBEERERHRlxIERURE\nRF9KEBQRERF9KUFQRERE9KX/DxmIZdL/svyOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a7d65f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = 1\n",
    "np_c, np_H, np_e0, np_psi0 = next_batch(D_side, batch_size=b)\n",
    "real_c = Variable(torch.Tensor(np_c))\n",
    "real_H = Variable(torch.Tensor(np_H))\n",
    "real_e0 = Variable(torch.Tensor(np_e0))\n",
    "real_psi0 = Variable(torch.Tensor(np_psi0))\n",
    "psi0_hat = model(real_c, batch_size=b) \n",
    "\n",
    "np_real_psi0 = real_psi0.data.numpy()\n",
    "np_psi0_hat = psi0_hat.data.numpy()\n",
    "\n",
    "sd, mn = np.std(np_real_psi0), np.mean(np_real_psi0)\n",
    "cl = [mn-2*sd,mn+2*sd]\n",
    "use_cl = True\n",
    "if use_cl: print(cl)\n",
    "\n",
    "f2 = plt.figure(figsize=[8,3])\n",
    "plt.subplot(211)\n",
    "plt.imshow(np_real_psi0) ; plt.title('exact $\\psi_0$')\n",
    "if use_cl: plt.clim(*cl)\n",
    "plt.subplot(212)\n",
    "im = plt.imshow(np_psi0_hat) ; plt.title('low-energy estimate $\\hat \\psi_{NN}$')\n",
    "if use_cl: plt.clim(*cl)\n",
    "\n",
    "cax = f2.add_axes([0.95, 0.15, 0.02, 0.7])\n",
    "cb = f2.colorbar(im, cax=cax, orientation='vertical')\n",
    "cb.set_label('color scale')\n",
    "\n",
    "plt.show() #; f2.savefig('./figures/H2psi0.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psi0_e: -2.7708 / e0_e: -2.7708\n",
      "psi1_e: -2.1704 / e1_e: -2.1704\n",
      "psi2_e: -1.7225 / e2_e: -1.7225\n",
      "hat psi0_e: -2.0703\n",
      "rand psi_e: 2.8301\n",
      "\n",
      "mean err nn  : 0.7006\n",
      "mean err rand: 2.8301\n",
      "\n",
      "mean err nn  : 25.2843%\n",
      "mean err rand: 102.1380%\n"
     ]
    }
   ],
   "source": [
    "b=500\n",
    "\n",
    "np_c, np_H, np_e0, np_psi0, np_e1, np_psi1, np_e2, np_psi2 = next_batch(D_side, batch_size=b, just_ground=False)\n",
    "real_c = Variable(torch.Tensor(np_c))\n",
    "real_H = Variable(torch.Tensor(np_H))\n",
    "real_e0 = Variable(torch.Tensor(np_e0))\n",
    "real_psi0 = Variable(torch.Tensor(np_psi0))\n",
    "real_e1 = Variable(torch.Tensor(np_e1))\n",
    "real_psi1 = Variable(torch.Tensor(np_psi1))\n",
    "real_e2 = Variable(torch.Tensor(np_e2))\n",
    "real_psi2 = Variable(torch.Tensor(np_psi2))\n",
    "psi0_hat = model(real_c, batch_size=b) \n",
    "\n",
    "psis = []\n",
    "for _ in range(b):\n",
    "    psis.append(rand_psi(D_side))\n",
    "rand_psis = Variable(torch.Tensor(np.vstack(psis)))\n",
    "\n",
    "psi0_e = energy_func(real_psi0, real_H, batch_size=b).data.numpy()\n",
    "psi1_e = energy_func(real_psi1, real_H, batch_size=b).data.numpy()\n",
    "psi2_e = energy_func(real_psi2, real_H, batch_size=b).data.numpy()\n",
    "e0_e = real_e0.data.numpy()\n",
    "e1_e = real_e1.data.numpy()\n",
    "e2_e = real_e2.data.numpy()\n",
    "psi0_hat_e = energy_func(psi0_hat, real_H, batch_size=b).data.numpy()\n",
    "rpsi_e = energy_func(rand_psis, real_H, batch_size=b).data.numpy()\n",
    "\n",
    "nn_e = np.mean(psi0_hat_e)\n",
    "mean_rpsi_e = np.mean(rpsi_e)\n",
    "\n",
    "mean_psi0_hat_e = np.mean(psi0_hat_e.ravel())\n",
    "mean_err_rand = np.mean(rpsi_e.ravel())\n",
    "\n",
    "mean_err_nn = np.mean(np.abs(e0_e.ravel() - psi0_hat_e.ravel()))\n",
    "mean_err_rand = np.mean(np.abs(e0_e.ravel() - rpsi_e.ravel()))\n",
    "\n",
    "mpe_nn = mean_err_nn / np.mean(np.abs(e0_e)) * 100\n",
    "mpe_rand = mean_err_rand / np.mean(np.abs(e0_e)) * 100\n",
    "\n",
    "print(\"psi0_e: {:.4f} / e0_e: {:.4f}\".format(np.mean(psi0_e), np.mean(e0_e)))\n",
    "print(\"psi1_e: {:.4f} / e1_e: {:.4f}\".format(np.mean(psi1_e), np.mean(e1_e)))\n",
    "print(\"psi2_e: {:.4f} / e2_e: {:.4f}\".format(np.mean(psi2_e), np.mean(e2_e)))\n",
    "print(\"hat psi0_e: {:.4f}\".format(mean_psi0_hat_e))\n",
    "print(\"rand psi_e: {:.4f}\\n\".format(mean_err_rand))\n",
    "\n",
    "print(\"mean err nn  : {:.4f}\".format( mean_err_nn) )\n",
    "print(\"mean err rand: {:.4f}\\n\".format( mean_err_rand))\n",
    "\n",
    "print(\"mean err nn  : {:.4f}%\".format(mpe_nn))\n",
    "print(\"mean err rand: {:.4f}%\".format(mpe_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAINCAYAAAC6QC01AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d64ca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "energies = [mean_psi0_hat_e, np.mean(e2_e), np.mean(e1_e), np.mean(e0_e)] #+ [mean_err_rand]\n",
    "labels = ['$E_{\\psi_{NN}}$', '$E_2$', '$E_1$', '$E_0$'] #+ ['$E_{rand}$', ]\n",
    "energies = np.vstack([energies]*2).T\n",
    "\n",
    "f3 = plt.figure(figsize=[3,9])\n",
    "for i, e in enumerate(energies):\n",
    "    plt.plot(e, linewidth=6.0)\n",
    "plt.title(\"Average energy\", fontsize=16)\n",
    "plt.legend(labels, ncol=1, fontsize=16, loc=(1.1,.33)) #, loc='upper right'\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.setp(plt.gca().axes.get_yticklabels(), fontsize=16)\n",
    "plt.show() #; f3.savefig('./figures/spectra.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the distribution of percent error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpes = np.abs(e0_e.ravel() - psi0_hat_e.ravel()) / np.mean(np.abs(e0_e)) * 100\n",
    "plt.hist(mpes, bins=40)\n",
    "plt.ylabel('Frequency') ; plt.xlabel('Percent error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the model sometimes choose second eigenvalues?\n",
    "\n",
    "Running this cell a couple (5-10 times) should reveal a prediction or two which is more similar to the first excited state than to the ground state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=1\n",
    "\n",
    "np_c, np_H, np_e0, np_psi0, np_e1, np_psi1, _, _ = next_batch(D_side, batch_size=b, just_ground=False)\n",
    "real_c = Variable(torch.Tensor(np_c))\n",
    "real_H = Variable(torch.Tensor(np_H))\n",
    "real_e0 = Variable(torch.Tensor(np_e0))\n",
    "real_psi0 = Variable(torch.Tensor(np_psi0))\n",
    "real_e1 = Variable(torch.Tensor(np_e1))\n",
    "real_psi1 = Variable(torch.Tensor(np_psi1))\n",
    "psi0_hat = model(real_c, batch_size=b) \n",
    "\n",
    "diff = psi0_hat - real_psi0\n",
    "psi1_hat = dot_norm(diff)\n",
    "\n",
    "np_real_psi0 = real_psi0.data.numpy()\n",
    "np_real_psi1 = real_psi1.data.numpy()\n",
    "np_psi1_hat = psi1_hat.data.numpy()\n",
    "\n",
    "sd, mn = np.std(np_real_psi1), np.mean(np_real_psi1)\n",
    "cl = [mn-2*sd,mn+2*sd]\n",
    "use_cl = True\n",
    "if use_cl: print(cl)\n",
    "\n",
    "f3 = plt.figure(figsize=[8,4])\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.imshow(np_real_psi0) ; plt.title('exact $\\psi_0$')\n",
    "if use_cl: plt.clim(*cl)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.subplot(312)\n",
    "im = plt.imshow(np_real_psi1) ; plt.title('exact $\\psi_1$')\n",
    "if use_cl: plt.clim(*cl)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.subplot(313)\n",
    "im = plt.imshow(np_psi1_hat) ; plt.title('estimated $\\psi_0$')\n",
    "if use_cl: plt.clim(*cl)\n",
    "plt.gca().axes.get_xaxis().set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "\n",
    "cax = f3.add_axes([0.95, 0.15, 0.02, 0.7])\n",
    "cb = f3.colorbar(im, cax=cax, orientation='vertical')\n",
    "cb.set_label('color scale')\n",
    "\n",
    "plt.show() #; f3.savefig('./figures/psi2-compare.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
