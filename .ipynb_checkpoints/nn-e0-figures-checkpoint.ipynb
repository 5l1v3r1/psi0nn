{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for estimating $H$ ground state energy\n",
    "Sam Greydanus. 5 May 2017. MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os, copy\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import kron, identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "lr = 1e-3\n",
    "global_step = 0\n",
    "print_every = 250\n",
    "total_steps = 10000\n",
    "cost_func = nn.L1Loss()\n",
    "\n",
    "d = 2\n",
    "chi = 4\n",
    "D_side = d**chi\n",
    "D_img = D_side**2\n",
    "D_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "Use the same free site as we've been using for DMRG runs. Change the coupling constants `J` and `Jz` randomly, try to estimate change in energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreeSite():\n",
    "    def __init__(self, J=None, Jz=None):\n",
    "        self.length = 1 # length\n",
    "        self.ops = ops = {}\n",
    "        self.J = J ; self.Jz = Jz\n",
    "        \n",
    "        # build operator dictionary\n",
    "        ops[\"H\"] = np.zeros((2,2)) # local Hamiltonian np.random.randn(2,2)\n",
    "        ops[\"Sz\"] = np.array([[0.5, 0], [0, -0.5]]) # z spin (S^z) operator\n",
    "        ops[\"Sp\"] = np.array([[0.0, 1.0], [0.0, 0.0]]) # raising (S^+) operator\n",
    "    \n",
    "    def get_dim(self):\n",
    "        return list(self.ops.values())[0].shape[0] # all ops should have same dimensionality\n",
    "        \n",
    "    def enlarge(self, site):\n",
    "        '''Enlarge block by a single site'''\n",
    "        \n",
    "        D1, H1, Sz1, Sp1 = self.get_dim(), self.ops['H'], self.ops['Sz'], self.ops['Sp'] # this block\n",
    "        D2, H2, Sz2, Sp2 = site.get_dim(), site.ops['H'], site.ops['Sz'], site.ops['Sp'] # another block (ie free site)\n",
    "\n",
    "        enlarged = copy.deepcopy(self)\n",
    "        enlarged.length += site.length\n",
    "        ops = enlarged.ops\n",
    "\n",
    "        ops['H'] = kron(H1, identity(D2)) + kron(identity(D1), H2) + self.interaction_H(site)\n",
    "        ops['Sz'] = kron(identity(D1), Sz2)\n",
    "        ops['Sp'] = kron(identity(D1), Sp2)\n",
    "\n",
    "        return enlarged\n",
    "    \n",
    "    def interaction_H(self, site):\n",
    "        '''Given another block, returns two-site term in the \n",
    "        Hamiltonain that joins the two sites.'''\n",
    "        Sz1, Sp1 = self.ops[\"Sz\"], self.ops[\"Sp\"] # this block\n",
    "        Sz2, Sp2 = site.ops[\"Sz\"], site.ops[\"Sp\"] # another block\n",
    "        \n",
    "        J = 1.*np.random.randn() if self.J is None else self.J\n",
    "        Jz = 1.*np.random.randn() if self.Jz is None else self.Jz\n",
    "        \n",
    "        join_Sp = (J/2)*(kron(Sp1, Sp2.conjugate().transpose()) + kron(Sp1.conjugate().transpose(), Sp2))\n",
    "        join_Sz = Jz*kron(Sz1, Sz2)\n",
    "        return (join_Sp + join_Sz)\n",
    "    \n",
    "    def rotate_ops(self, transformation_matrix):\n",
    "        # rotate and truncate each operator.\n",
    "        new_ops = {}\n",
    "        for name, op in self.ops.items():\n",
    "            new_ops[name] = self.rotate_and_truncate(op, transformation_matrix)\n",
    "        self.ops = new_ops\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate_and_truncate(S, O):\n",
    "        '''Transforms the operator to a new (possibly truncated) basis'''\n",
    "        return O.conjugate().transpose().dot(S.dot(O)) # eqn 7 in arXiv:cond-mat/0603842v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-95a0738ee9a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_side\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4-site hamiltonian w random $J$ and $J_z$ couplings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fs = FreeSite()\n",
    "\n",
    "def hamiltonian(d, free_site):\n",
    "    sys = free_site\n",
    "    for _ in range(d):\n",
    "        sys = sys.enlarge(free_site)\n",
    "    return sys.ops['H']\n",
    "\n",
    "def next_batch(D):\n",
    "    H = hamiltonian(d=3, free_site=fs).todense()\n",
    "    e0, psi0 = eigsh(H,k=1)\n",
    "    return np.asarray(H), e0, psi0\n",
    "\n",
    "H, e0, psi0 = next_batch(D_side)\n",
    "plt.title(\"4-site hamiltonian w random $J$ and $J_z$ couplings\")\n",
    "plt.imshow(H) ; plt.show()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title(\"Ground state $\\psi_0$ ($E_0={:.4f}$)\".format(e0[0]))\n",
    "plt.imshow(psi0.T) ; plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generic CNN, see github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=2)\n",
    "        self.conv1_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(490, D_hidden)\n",
    "        self.fc2 = nn.Linear(D_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H = x.resize(batch_size,1,D_side,D_side)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(H), 2))\n",
    "        x = x.view(-1, 490)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        e0_hat = self.fc2(x)\n",
    "        return e0_hat\n",
    "    \n",
    "# a vanilla neural network with one hidden layer\n",
    "class SimpleNN2(torch.nn.Module):\n",
    "    def __init__(self, batch_size, input_dim, h_dim, output_dim):\n",
    "        super(SimpleNN2, self).__init__()\n",
    "        self.W1 = nn.Parameter(torch.randn(input_dim, h_dim)*0.075)\n",
    "        self.b1 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W2 = nn.Parameter(torch.randn(h_dim, output_dim)*0.075)\n",
    "        self.b2 = nn.Parameter(torch.randn(output_dim)*0.075)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.resize(1,D_img)\n",
    "        h1 = F.relu(X.mm(self.W1) + self.b1.repeat(X.size(0), 1))\n",
    "        h2 = h1.mm(self.W2) + self.b2.repeat(X.size(0), 1)\n",
    "        return h2\n",
    "    \n",
    "# a vanilla neural network with one hidden layer\n",
    "class SimpleNN3(torch.nn.Module):\n",
    "    def __init__(self, batch_size, input_dim, h_dim, output_dim):\n",
    "        super(SimpleNN3, self).__init__()\n",
    "        self.W1 = nn.Parameter(torch.randn(input_dim, h_dim)*0.075)\n",
    "        self.b1 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W2 = nn.Parameter(torch.randn(h_dim, h_dim)*0.075)\n",
    "        self.b2 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W3 = nn.Parameter(torch.randn(h_dim, output_dim)*0.075)\n",
    "        self.b3 = nn.Parameter(torch.randn(output_dim)*0.075)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.resize(1,D_img)\n",
    "        h1 = F.relu(X.mm(self.W1) + self.b1.repeat(X.size(0), 1))\n",
    "        h2 = F.relu(h1.mm(self.W2) + self.b2.repeat(X.size(0), 1))\n",
    "        h3 = h2.mm(self.W3) + self.b3.repeat(X.size(0), 1)\n",
    "        return h3\n",
    "    \n",
    "# model = SimpleCNN()\n",
    "model = SimpleNN3(batch_size=1, input_dim=D_img, h_dim=D_hidden, output_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model to estimate ground state energies\n",
    "Takes ~30 min to train on my MacBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "running_loss = None\n",
    "# generic train loop\n",
    "for global_step in range(global_step, total_steps+global_step):\n",
    "    \n",
    "    # ======== DISCRIMINATOR STEP ======== #\n",
    "    # forward\n",
    "    np_H, np_e0, np_psi0 = next_batch(D_side)\n",
    "    real_H = Variable(torch.Tensor(np_H))\n",
    "    real_e0 = Variable(torch.Tensor(np_e0))\n",
    "    e0_hat = model(real_H) \n",
    "\n",
    "    # backward\n",
    "    loss = cost_func(e0_hat, real_e0)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    running_loss = loss.data.numpy()[0] if running_loss is None else .99*running_loss + (1-.99)*loss.data.numpy()[0]\n",
    "\n",
    "    # ======== DISPLAY PROGRESS ======== #\n",
    "    if global_step % print_every == 0:\n",
    "        print('step {}: loss: {:.4f}'.format(global_step, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample model and compare real e0 with model's estimates\n",
    "for _ in range(10):\n",
    "    H, e0, psi0 = next_batch(D_side)\n",
    "    real_H = Variable(torch.Tensor(H)) #.resize(batch_size,1,D_side,D_side)\n",
    "    e0_hat = model(real_H)\n",
    "    print(\"pred: {:6f}, real: {:6f}\".format(e0_hat.data.numpy()[0][0], e0[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure mean error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample model and compare real e0 with model's estimates\n",
    "k = 100\n",
    "real_e0 = np.zeros(k)\n",
    "est_e0 = np.zeros(k)\n",
    "for i in range(k):\n",
    "    H, e0, psi0 = next_batch(D_side)\n",
    "    real_H = Variable(torch.Tensor(H)) #.resize(batch_size,1,D_side,D_side)\n",
    "    e0_hat = model(real_H)\n",
    "    real_e0[i] = e0[0]\n",
    "    est_e0[i] = e0_hat.data.numpy()[0][0]\n",
    "mean_percent_error_model = np.mean(np.abs(real_e0 - est_e0))\n",
    "mean_percent_error_avg = np.mean(np.abs(real_e0 - np.ones_like(est_e0)*np.mean(real_e0)))\n",
    "print(\"Mean error of guessing average {:.4f}\".format(mean_percent_error_avg))\n",
    "print(\"Mean error of model {:.4f}\".format(mean_percent_error_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure mean % error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample model and compare real e0 with model's estimates\n",
    "k = 100\n",
    "real_e0 = np.zeros(k)\n",
    "est_e0 = np.zeros(k)\n",
    "for i in range(k):\n",
    "    H, e0, psi0 = next_batch(D_side)\n",
    "    real_H = Variable(torch.Tensor(H)) #.resize(batch_size,1,D_side,D_side)\n",
    "    e0_hat = model(real_H)\n",
    "    real_e0[i] = e0[0]\n",
    "    est_e0[i] = e0_hat.data.numpy()[0][0]\n",
    "mean_percent_error_model = np.mean(np.abs(real_e0 - est_e0) / np.abs(real_e0))*100\n",
    "mean_percent_error_avg = np.mean(np.abs(real_e0 - np.ones_like(est_e0)*np.mean(real_e0)) / np.abs(real_e0))*100\n",
    "print(\"Mean % error of guessing average {:.2f}%\".format(mean_percent_error_avg))\n",
    "print(\"Mean % error of model {:.2f}%\".format(mean_percent_error_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well has the NN approximated this system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ham(J, Jz):\n",
    "    sys = FreeSite(J=J, Jz=Jz)\n",
    "    for _ in range(3):\n",
    "        fs = FreeSite(J=J, Jz=Jz)\n",
    "        sys = sys.enlarge(fs)\n",
    "    return sys.ops['H'].todense()\n",
    "\n",
    "def get_estimates(strengths, c, term='J'):\n",
    "    e0_list = np.zeros_like(strengths)\n",
    "    e0_hat_list = np.zeros_like(strengths)\n",
    "    for i in range(len(strengths)):\n",
    "        H = ham(J=strengths[i], Jz=c) if term == \"J\" else ham(J=c, Jz=strengths[i])\n",
    "        (e0,), psi0 = eigsh(H,k=1)\n",
    "        e0_list[i] = e0\n",
    "\n",
    "        H = np.asarray(H)\n",
    "        real_H = Variable(torch.Tensor(H))\n",
    "        e0_hat = model(real_H)\n",
    "        e0_hat_list[i] = e0_hat.data.numpy()[0][0]\n",
    "    return e0_list, e0_hat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minx, maxx = -1., 1.\n",
    "fs = [12,8]\n",
    "k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make data\n",
    "strengths = np.linspace(minx, maxx, k)\n",
    "jz_range = [-1., -.1, 0.1, 1.]\n",
    "j_list = []\n",
    "for jz in jz_range:\n",
    "    e0_list, e0_hat_list = get_estimates(strengths, c=jz, term='J')\n",
    "    j_list.append((jz, (e0_list, e0_hat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "f1 = plt.figure(figsize=fs)\n",
    "\n",
    "f1.text(0.5, .95, 'Estimating $E_0$ for fixed $J_z$', ha='center', va='center', fontsize=14)\n",
    "f1.text(0.5, 0.04, '$J$ coupling term', ha='center', va='center')\n",
    "f1.text(0.06, 0.5, 'Ground state energy ($E_{0}$)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $J$ for fixed $J_z={:.2f}$\".format(j_list[0][0]))\n",
    "e0_list = j_list[0][1][0] ; e0_hat_list = j_list[0][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $J$ for fixed $J_z={:.2f}$\".format(j_list[1][0]))\n",
    "e0_list = j_list[1][1][0] ; e0_hat_list = j_list[1][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $J$ for fixed $J_z={:.2f}$\".format(j_list[2][0]))\n",
    "e0_list = j_list[2][1][0] ; e0_hat_list = j_list[2][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $J$ for fixed $J_z={:.2f}$\".format(j_list[3][0]))\n",
    "e0_list = j_list[3][1][0] ; e0_hat_list = j_list[3][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "    \n",
    "plt.show() ; pp = PdfPages('./figures/nn-J-coupling.pdf') ; pp.savefig(f1) ; pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make data\n",
    "strengths = np.linspace(minx, maxx, k)\n",
    "j_range = [-1., -.1, 0.1, 1.]\n",
    "jz_list = []\n",
    "for j in j_range:\n",
    "    e0_list, e0_hat_list = get_estimates(strengths, c=j, term='Jz')\n",
    "    jz_list.append((j, (e0_list, e0_hat_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "f2 = plt.figure(figsize=fs)\n",
    "\n",
    "f2.text(0.5, .95, 'Estimating $E_0$ for fixed $J$', ha='center', va='center', fontsize=14)\n",
    "f2.text(0.5, 0.04, '$J_z$ coupling term', ha='center', va='center')\n",
    "f2.text(0.06, 0.5, 'Ground state energy ($E_{0}$)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "i = 0\n",
    "plt.subplot(221)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $Jz$ for fixed $J={:.2f}$\".format(jz_list[i][0]))\n",
    "e0_list = jz_list[i][1][0] ; e0_hat_list = jz_list[i][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "\n",
    "i = 1\n",
    "plt.subplot(222)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $Jz$ for fixed $J={:.2f}$\".format(jz_list[i][0]))\n",
    "e0_list = jz_list[i][1][0] ; e0_hat_list = jz_list[i][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "\n",
    "i = 2\n",
    "plt.subplot(223)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $Jz$ for fixed $J={:.2f}$\".format(jz_list[i][0]))\n",
    "e0_list = jz_list[i][1][0] ; e0_hat_list = jz_list[i][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "\n",
    "i = 3\n",
    "plt.subplot(224)\n",
    "plt.axis([minx - 0.2, maxx + 0.2, -1.8, 1.8])\n",
    "plt.title(\"Varying $Jz$ for fixed $J={:.2f}$\".format(jz_list[i][0]))\n",
    "e0_list = jz_list[i][1][0] ; e0_hat_list = jz_list[i][1][1]\n",
    "plt.plot(strengths, e0_list, label=\"ground truth\")\n",
    "plt.plot(strengths, e0_hat_list, '*r', label=\"NN estimate\") ; legend()\n",
    "    \n",
    "plt.show() ; plt.show() ; pp = PdfPages('./figures/nn-Jz-coupling.pdf') ; pp.savefig(f2) ; pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
