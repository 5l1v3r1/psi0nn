{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try solving for MPS coefficients of GHZ state with an Autoencoder\n",
    "\n",
    "Sam Greydanus. March 2017. MIT License.\n",
    "\n",
    "Brief explanation and live demo of autoencoder [here](https://cs.stanford.edu/people/karpathy/convnetjs/demo/autoencoder.html). Wikipedia article [here](https://en.wikipedia.org/wiki/Autoencoder).\n",
    "\n",
    "<img src=\"static/autoencoder.png\" alt=\"Finite DMRG base case\" style=\"width: 40%;\"/>\n",
    "\n",
    "I modify the decoder part. Instead of being a neural network, I use the definition of reconstructing a state using MPS coefficients\n",
    "\n",
    "**Note:** This is a PyTorch implementation. I also wrote a TensorFlow implementation of this autoencoder; it's in the `_deprecated` folder. I like PyTorch; it's easier to write and debug. That said, both frameworks work fine for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import glob, copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "np.random.seed(seed=123) # for reproducibility\n",
    "ms = torch.manual_seed(123) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "Simple functions that might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def llprint(message):\n",
    "    sys.stdout.write(message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def baseN(num, b, numerals=\"0123456789abcdefghijklmnopqrstuvwxyz\"):\n",
    "    return ((num == 0) and numerals[0]) or (baseN(num // b, b, numerals).lstrip(numerals[0]) + numerals[num % b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 'decode' portion\n",
    "These functions are written for PyTorch tensors. PyTorch uses lazy execution, meaning that it builds an optimized computational graph and only executes the operations in that graph after a request. See http://pytorch.org/ for a good series of introductory tutorials. Unlike TensorFlow, PyTorch supports dynamic graphs. This makes it more flexible and, in my opinion, easier to write and debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mps2state(A_list):\n",
    "    '''given a list of mps coefficients, returns the state of the full system.\n",
    "    The input A_list is indexed according to A_list[{local state}][{local site}].'''\n",
    "    d = len(A_list) # number of possible states\n",
    "    chi = len(A_list[0]) # number of possible sites\n",
    "    c = [] # the state\n",
    "    for sys_state in range(d**chi): # loop over \n",
    "        ix = baseN(sys_state, d).zfill(len(A_list[0]))\n",
    "        for site in range(chi):\n",
    "            site_state = A_list[int(ix[site])][site]\n",
    "            prod = site_state if site is 0 else torch.mm(prod, site_state) # matrix multiplication (contract tensors)\n",
    "        c.append(torch.trace(prod))\n",
    "    return torch.stack(c)\n",
    "\n",
    "def coeff2mps(coeff, d, chi):\n",
    "    '''given a vector of coefficients of length chi*d^3, reshapes them into an A_list\n",
    "    that can be passed to mps2state function above'''\n",
    "    splits = torch.split(coeff,d*d,dim=1)\n",
    "    dxd_splits = [c.resize(d,d) for c in splits]\n",
    "    A_list = [dxd_splits[d_i*chi:(1+d_i)*chi] for d_i in range(d)]\n",
    "    return A_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder 'encode' portion\n",
    "We'll use a 2-layer neural network with 1024 hidden units and relu activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "lr = 3e-4 # learning rate\n",
    "batch_size = 1 # batch size for minibatch gradient descent\n",
    "save_dir = 'psi2psi-sigmoid_models'\n",
    "checkpoint_steps = [1, 10,30,100,300,1000,3000,10000,30000,100000,300000]\n",
    "checkpoint_steps += [250, 500, 1000, 2000, 4000, 16000, 64000, 128000]\n",
    "total_steps = max(checkpoint_steps + [10000])\n",
    "print_every = 500\n",
    "global_step = 0 # keeps track of current step of gradient descent\n",
    "d = 2 # number of quantum states available to each site\n",
    "chi = 4 # number of sites (ie electrons)\n",
    "\n",
    "D_side = d**chi # autoencoder input dimensionality\n",
    "D_hidden = 512 # dimensionality of hidden layer(s)\n",
    "D_mps = d*chi*d*d # dimensionality of MPS 'coeff' vector\n",
    "cost_func = nn.PairwiseDistance() # square and sum to get L2 loss (see train loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a neural network with three hidden layers\n",
    "class SimpleNN3(torch.nn.Module):\n",
    "    def __init__(self, batch_size, input_dim, h_dim, output_dim):\n",
    "        super(SimpleNN3, self).__init__()\n",
    "        self.W1 = nn.Parameter(torch.randn(input_dim, h_dim)*0.075)\n",
    "        self.b1 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W2 = nn.Parameter(torch.randn(h_dim, h_dim)*0.075)\n",
    "        self.b2 = nn.Parameter(torch.randn(h_dim)*0.075)\n",
    "        self.W3 = nn.Parameter(torch.randn(h_dim, output_dim)*0.075)\n",
    "        self.b3 = nn.Parameter(torch.randn(output_dim)*0.075)\n",
    "        self.arch = 'SimpleNN3'\n",
    "\n",
    "    def forward(self, X, batch_size):\n",
    "        h1 = F.relu(X.mm(self.W1) + self.b1.repeat(X.size(0), 1))\n",
    "        h2 = F.relu(h1.mm(self.W2) + self.b2.repeat(X.size(0), 1))\n",
    "        h3 = h2.mm(self.W3) + self.b3.repeat(X.size(0), 1)\n",
    "        h3 = F.sigmoid(h3)\n",
    "        return h3\n",
    "    \n",
    "model = SimpleNN3(batch_size=1, input_dim=D_side, h_dim=D_hidden, output_dim=D_mps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full Autoencoder forward pass\n",
    "First encode with the neural network, then decode using the definition of MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(X, model):\n",
    "    '''defines one forward pass of the neural network encoder. The input is the\n",
    "    full-dimension state vector of the system and the output is an attempt at\n",
    "    reconstructing the input vector after compressing it as a set of MPS coefficients'''\n",
    "    coeff = model(X, batch_size)\n",
    "    \n",
    "    A_list = coeff2mps(coeff, d, chi) # repackage output vector as a list of A matrices\n",
    "    psi_hat = mps2state(A_list) # reconstruct the original state vector from these A matrices by definition of MPS\n",
    "    return psi_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "In order to train the model, we need data. In this case, I'll just choose each example state vector to be a random d^chi vector such that the dot product of the vector with its conjugate transpose is normalized (a necessary property of a state vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31199448  0.12818068  0.10162173  0.24697024  0.3222976   0.18953729\n",
      "   0.43934896  0.3067804   0.21544112  0.1756553   0.15373207  0.32658944\n",
      "   0.19646543  0.02673367  0.17831027  0.33059681]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def next_batch(D_side):\n",
    "    psi = np.random.rand(1, D_side)\n",
    "    psi /= np.sqrt(np.dot(psi, psi.T))\n",
    "    return psi\n",
    "k = next_batch(D_side)\n",
    "print(k) ; print(np.dot(k, k.conjugate().T)[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global_step = 0\n",
    "# load_was_success = True # yes, I'm being optimistic\n",
    "# model_zoo = []\n",
    "# paths = glob.glob(save_dir + '/*.tar')\n",
    "# try:\n",
    "#     for s in paths:\n",
    "#         checkpoint = torch.load(s)\n",
    "#         model.load_state_dict(checkpoint['state_dict'])\n",
    "#         global_step = checkpoint['global_step']\n",
    "#         model_zoo.append((global_step, copy.deepcopy(model)))\n",
    "#         print(\"loaded model: {}\".format(s))\n",
    "#     model_zoo = sorted(model_zoo, key=lambda tup: tup[0])\n",
    "#     global_step, model = model_zoo[-1]\n",
    "# except:\n",
    "#     print(\"no saved model to load.\") ; model_zoo = []\n",
    "#     load_was_success = False\n",
    "# else:\n",
    "#     if len(paths) is 0: print(\"no saved model to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Display the loss every so often. It should be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss: 6.4685\n",
      "\tstep 1: saved model\n",
      "\tstep 10: saved model\n",
      "\tstep 30: saved model\n",
      "\tstep 100: saved model\n",
      "\tstep 250: saved model\n",
      "\tstep 300: saved model\n",
      "step 500: loss: 0.1525\n",
      "\tstep 500: saved model\n",
      "step 1000: loss: 0.0877\n",
      "\tstep 1000: saved model\n",
      "step 1500: loss: 0.0741\n",
      "step 2000: loss: 0.0526\n",
      "\tstep 2000: saved model\n",
      "step 2500: loss: 0.0458\n",
      "step 3000: loss: 0.0463\n",
      "\tstep 3000: saved model\n",
      "step 3500: loss: 0.0445\n",
      "step 4000: loss: 0.0449\n",
      "\tstep 4000: saved model\n",
      "step 4500: loss: 0.0460\n",
      "step 5000: loss: 0.0451\n",
      "step 5500: loss: 0.0431\n",
      "step 6000: loss: 0.0446\n",
      "step 6500: loss: 0.0437\n",
      "step 7000: loss: 0.0456\n",
      "step 7500: loss: 0.0417\n",
      "step 8000: loss: 0.0417\n",
      "step 8500: loss: 0.0432\n",
      "step 9000: loss: 0.0402\n",
      "step 9500: loss: 0.0398\n",
      "step 10000: loss: 0.0392\n",
      "\tstep 10000: saved model\n",
      "step 10500: loss: 0.0410\n",
      "step 11000: loss: 0.0400\n",
      "step 11500: loss: 0.0393\n",
      "step 12000: loss: 0.0378\n",
      "step 12500: loss: 0.0406\n",
      "step 13000: loss: 0.0373\n",
      "step 13500: loss: 0.0387\n",
      "step 14000: loss: 0.0377\n",
      "step 14500: loss: 0.0362\n",
      "step 15000: loss: 0.0355\n",
      "step 15500: loss: 0.0361\n",
      "step 16000: loss: 0.0369\n",
      "\tstep 16000: saved model\n",
      "step 16500: loss: 0.0365\n",
      "step 17000: loss: 0.0358\n",
      "step 17500: loss: 0.0369\n",
      "step 18000: loss: 0.0357\n",
      "step 18500: loss: 0.0348\n",
      "step 19000: loss: 0.0360\n",
      "step 19500: loss: 0.0353\n",
      "step 20000: loss: 0.0338\n",
      "step 20500: loss: 0.0354\n",
      "step 21000: loss: 0.0348\n",
      "step 21500: loss: 0.0330\n",
      "step 22000: loss: 0.0346\n",
      "step 22500: loss: 0.0346\n",
      "step 23000: loss: 0.0323\n",
      "step 23500: loss: 0.0321\n",
      "step 24000: loss: 0.0319\n",
      "step 24500: loss: 0.0311\n",
      "step 25000: loss: 0.0317\n",
      "step 25500: loss: 0.0327\n",
      "step 26000: loss: 0.0331\n",
      "step 26500: loss: 0.0342\n",
      "step 27000: loss: 0.0338\n",
      "step 27500: loss: 0.0319\n",
      "step 28000: loss: 0.0316\n",
      "step 28500: loss: 0.0323\n",
      "step 29000: loss: 0.0310\n",
      "step 29500: loss: 0.0331\n",
      "step 30000: loss: 0.0295\n",
      "\tstep 30000: saved model\n",
      "step 30500: loss: 0.0307\n",
      "step 31000: loss: 0.0318\n",
      "step 31500: loss: 0.0351\n",
      "step 32000: loss: 0.0318\n",
      "step 32500: loss: 0.0321\n",
      "step 33000: loss: 0.0347\n",
      "step 33500: loss: 0.0311\n",
      "step 34000: loss: 0.0369\n",
      "step 34500: loss: 0.0354\n",
      "step 35000: loss: 0.0328\n",
      "step 35500: loss: 0.0318\n",
      "step 36000: loss: 0.0290\n",
      "step 36500: loss: 0.0320\n",
      "step 37000: loss: 0.0311\n",
      "step 37500: loss: 0.0319\n",
      "step 38000: loss: 0.0308\n",
      "step 38500: loss: 0.0324\n",
      "step 39000: loss: 0.0300\n",
      "step 39500: loss: 0.0335\n",
      "step 40000: loss: 0.0299\n",
      "step 40500: loss: 0.0337\n",
      "step 41000: loss: 0.0304\n",
      "step 41500: loss: 0.0305\n",
      "step 42000: loss: 0.0291\n",
      "step 42500: loss: 0.0308\n",
      "step 43000: loss: 0.0330\n",
      "step 43500: loss: 0.0306\n",
      "step 44000: loss: 0.0318\n",
      "step 44500: loss: 0.0306\n",
      "step 45000: loss: 0.0314\n",
      "step 45500: loss: 0.0327\n",
      "step 46000: loss: 0.0310\n",
      "step 46500: loss: 0.0329\n",
      "step 47000: loss: 0.0308\n",
      "step 47500: loss: 0.0313\n",
      "step 48000: loss: 0.0278\n",
      "step 48500: loss: 0.0307\n",
      "step 49000: loss: 0.0331\n",
      "step 49500: loss: 0.0307\n",
      "step 50000: loss: 0.0296\n",
      "step 50500: loss: 0.0306\n",
      "step 51000: loss: 0.0305\n",
      "step 51500: loss: 0.0292\n",
      "step 52000: loss: 0.0295\n",
      "step 52500: loss: 0.0299\n",
      "step 53000: loss: 0.0340\n",
      "step 53500: loss: 0.0345\n",
      "step 54000: loss: 0.0316\n",
      "step 54500: loss: 0.0298\n",
      "step 55000: loss: 0.0317\n",
      "step 55500: loss: 0.0312\n",
      "step 56000: loss: 0.0303\n",
      "step 56500: loss: 0.0319\n",
      "step 57000: loss: 0.0331\n",
      "step 57500: loss: 0.0290\n",
      "step 58000: loss: 0.0346\n",
      "step 58500: loss: 0.0310\n",
      "step 59000: loss: 0.0315\n",
      "step 59500: loss: 0.0301\n",
      "step 60000: loss: 0.0315\n",
      "step 60500: loss: 0.0329\n",
      "step 61000: loss: 0.0302\n",
      "step 61500: loss: 0.0297\n",
      "step 62000: loss: 0.0315\n",
      "step 62500: loss: 0.0275\n",
      "step 63000: loss: 0.0301\n",
      "step 63500: loss: 0.0319\n",
      "step 64000: loss: 0.0328\n",
      "\tstep 64000: saved model\n",
      "step 64500: loss: 0.0307\n",
      "step 65000: loss: 0.0325\n",
      "step 65500: loss: 0.0299\n",
      "step 66000: loss: 0.0288\n",
      "step 66500: loss: 0.0307\n",
      "step 67000: loss: 0.0298\n",
      "step 67500: loss: 0.0326\n",
      "step 68000: loss: 0.0308\n",
      "step 68500: loss: 0.0294\n",
      "step 69000: loss: 0.0310\n",
      "step 69500: loss: 0.0289\n",
      "step 70000: loss: 0.0287\n",
      "step 70500: loss: 0.0307\n",
      "step 71000: loss: 0.0308\n",
      "step 71500: loss: 0.0291\n",
      "step 72000: loss: 0.0304\n",
      "step 72500: loss: 0.0303\n",
      "step 73000: loss: 0.0299\n",
      "step 73500: loss: 0.0319\n",
      "step 74000: loss: 0.0318\n",
      "step 74500: loss: 0.0303\n",
      "step 75000: loss: 0.0286\n",
      "step 75500: loss: 0.0304\n",
      "step 76000: loss: 0.0293\n",
      "step 76500: loss: 0.0311\n",
      "step 77000: loss: 0.0308\n",
      "step 77500: loss: 0.0311\n",
      "step 78000: loss: 0.0308\n",
      "step 78500: loss: 0.0297\n",
      "step 79000: loss: 0.0301\n",
      "step 79500: loss: 0.0322\n",
      "step 80000: loss: 0.0278\n",
      "step 80500: loss: 0.0312\n",
      "step 81000: loss: 0.0311\n",
      "step 81500: loss: 0.0281\n",
      "step 82000: loss: 0.0272\n",
      "step 82500: loss: 0.0282\n",
      "step 83000: loss: 0.0282\n",
      "step 83500: loss: 0.0257\n",
      "step 84000: loss: 0.0314\n",
      "step 84500: loss: 0.0295\n",
      "step 85000: loss: 0.0286\n",
      "step 85500: loss: 0.0311\n",
      "step 86000: loss: 0.0292\n",
      "step 86500: loss: 0.0293\n",
      "step 87000: loss: 0.0297\n",
      "step 87500: loss: 0.0293\n",
      "step 88000: loss: 0.0291\n",
      "step 88500: loss: 0.0287\n",
      "step 89000: loss: 0.0310\n",
      "step 89500: loss: 0.0302\n",
      "step 90000: loss: 0.0271\n",
      "step 90500: loss: 0.0269\n",
      "step 91000: loss: 0.0295\n",
      "step 91500: loss: 0.0301\n",
      "step 92000: loss: 0.0285\n",
      "step 92500: loss: 0.0290\n",
      "step 93000: loss: 0.0270\n",
      "step 93500: loss: 0.0303\n",
      "step 94000: loss: 0.0283\n",
      "step 94500: loss: 0.0284\n",
      "step 95000: loss: 0.0298\n",
      "step 95500: loss: 0.0293\n",
      "step 96000: loss: 0.0287\n",
      "step 96500: loss: 0.0307\n",
      "step 97000: loss: 0.0296\n",
      "step 97500: loss: 0.0264\n",
      "step 98000: loss: 0.0285\n",
      "step 98500: loss: 0.0280\n",
      "step 99000: loss: 0.0280\n",
      "step 99500: loss: 0.0291\n",
      "step 100000: loss: 0.0274\n",
      "\tstep 100000: saved model\n",
      "step 100500: loss: 0.0295\n",
      "step 101000: loss: 0.0286\n",
      "step 101500: loss: 0.0297\n",
      "step 102000: loss: 0.0287\n",
      "step 102500: loss: 0.0308\n",
      "step 103000: loss: 0.0266\n",
      "step 103500: loss: 0.0270\n",
      "step 104000: loss: 0.0288\n",
      "step 104500: loss: 0.0290\n",
      "step 105000: loss: 0.0268\n",
      "step 105500: loss: 0.0260\n",
      "step 106000: loss: 0.0301\n",
      "step 106500: loss: 0.0277\n",
      "step 107000: loss: 0.0293\n",
      "step 107500: loss: 0.0294\n",
      "step 108000: loss: 0.0299\n",
      "step 108500: loss: 0.0273\n",
      "step 109000: loss: 0.0273\n",
      "step 109500: loss: 0.0273\n",
      "step 110000: loss: 0.0286\n",
      "step 110500: loss: 0.0262\n",
      "step 111000: loss: 0.0269\n",
      "step 111500: loss: 0.0283\n",
      "step 112000: loss: 0.0292\n",
      "step 112500: loss: 0.0283\n",
      "step 113000: loss: 0.0271\n",
      "step 113500: loss: 0.0286\n",
      "step 114000: loss: 0.0262\n",
      "step 114500: loss: 0.0278\n",
      "step 115000: loss: 0.0268\n",
      "step 115500: loss: 0.0260\n",
      "step 116000: loss: 0.0276\n",
      "step 116500: loss: 0.0273\n",
      "step 117000: loss: 0.0269\n",
      "step 117500: loss: 0.0278\n",
      "step 118000: loss: 0.0284\n",
      "step 118500: loss: 0.0264\n",
      "step 119000: loss: 0.0282\n",
      "step 119500: loss: 0.0263\n",
      "step 120000: loss: 0.0279\n",
      "step 120500: loss: 0.0279\n",
      "step 121000: loss: 0.0260\n",
      "step 121500: loss: 0.0269\n",
      "step 122000: loss: 0.0269\n",
      "step 122500: loss: 0.0289\n",
      "step 123000: loss: 0.0265\n",
      "step 123500: loss: 0.0254\n",
      "step 124000: loss: 0.0264\n",
      "step 124500: loss: 0.0286\n",
      "step 125000: loss: 0.0268\n",
      "step 125500: loss: 0.0268\n",
      "step 126000: loss: 0.0264\n",
      "step 126500: loss: 0.0277\n",
      "step 127000: loss: 0.0258\n",
      "step 127500: loss: 0.0262\n",
      "step 128000: loss: 0.0252\n",
      "\tstep 128000: saved model\n",
      "step 128500: loss: 0.0259\n",
      "step 129000: loss: 0.0291\n",
      "step 129500: loss: 0.0278\n",
      "step 130000: loss: 0.0290\n",
      "step 130500: loss: 0.0282\n",
      "step 131000: loss: 0.0272\n",
      "step 131500: loss: 0.0265\n",
      "step 132000: loss: 0.0250\n",
      "step 132500: loss: 0.0256\n",
      "step 133000: loss: 0.0250\n",
      "step 133500: loss: 0.0245\n",
      "step 134000: loss: 0.0265\n",
      "step 134500: loss: 0.0279\n",
      "step 135000: loss: 0.0253\n",
      "step 135500: loss: 0.0280\n",
      "step 136000: loss: 0.0253\n",
      "step 136500: loss: 0.0255\n",
      "step 137000: loss: 0.0258\n",
      "step 137500: loss: 0.0277\n",
      "step 138000: loss: 0.0272\n",
      "step 138500: loss: 0.0252\n",
      "step 139000: loss: 0.0281\n",
      "step 139500: loss: 0.0269\n",
      "step 140000: loss: 0.0249\n",
      "step 140500: loss: 0.0260\n",
      "step 141000: loss: 0.0268\n",
      "step 141500: loss: 0.0256\n",
      "step 142000: loss: 0.0260\n",
      "step 142500: loss: 0.0258\n",
      "step 143000: loss: 0.0265\n",
      "step 143500: loss: 0.0238\n",
      "step 144000: loss: 0.0273\n",
      "step 144500: loss: 0.0268\n",
      "step 145000: loss: 0.0251\n",
      "step 145500: loss: 0.0258\n",
      "step 146000: loss: 0.0255\n",
      "step 146500: loss: 0.0257\n",
      "step 147000: loss: 0.0262\n",
      "step 147500: loss: 0.0256\n",
      "step 148000: loss: 0.0247\n",
      "step 148500: loss: 0.0259\n",
      "step 149000: loss: 0.0266\n",
      "step 149500: loss: 0.0254\n",
      "step 150000: loss: 0.0256\n",
      "step 150500: loss: 0.0260\n",
      "step 151000: loss: 0.0247\n",
      "step 151500: loss: 0.0266\n",
      "step 152000: loss: 0.0267\n",
      "step 152500: loss: 0.0260\n",
      "step 153000: loss: 0.0261\n",
      "step 153500: loss: 0.0252\n",
      "step 154000: loss: 0.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 154500: loss: 0.0254\n",
      "step 155000: loss: 0.0257\n",
      "step 155500: loss: 0.0230\n",
      "step 156000: loss: 0.0260\n",
      "step 156500: loss: 0.0248\n",
      "step 157000: loss: 0.0241\n",
      "step 157500: loss: 0.0229\n",
      "step 158000: loss: 0.0261\n",
      "step 158500: loss: 0.0255\n",
      "step 159000: loss: 0.0257\n",
      "step 159500: loss: 0.0251\n",
      "step 160000: loss: 0.0229\n",
      "step 160500: loss: 0.0242\n",
      "step 161000: loss: 0.0239\n",
      "step 161500: loss: 0.0255\n",
      "step 162000: loss: 0.0238\n",
      "step 162500: loss: 0.0264\n",
      "step 163000: loss: 0.0242\n",
      "step 163500: loss: 0.0266\n",
      "step 164000: loss: 0.0245\n",
      "step 164500: loss: 0.0269\n",
      "step 165000: loss: 0.0256\n",
      "step 165500: loss: 0.0253\n",
      "step 166000: loss: 0.0237\n",
      "step 166500: loss: 0.0233\n",
      "step 167000: loss: 0.0260\n",
      "step 167500: loss: 0.0241\n",
      "step 168000: loss: 0.0242\n",
      "step 168500: loss: 0.0269\n",
      "step 169000: loss: 0.0253\n",
      "step 169500: loss: 0.0230\n",
      "step 170000: loss: 0.0244\n",
      "step 170500: loss: 0.0256\n",
      "step 171000: loss: 0.0245\n",
      "step 171500: loss: 0.0260\n",
      "step 172000: loss: 0.0253\n",
      "step 172500: loss: 0.0243\n",
      "step 173000: loss: 0.0244\n",
      "step 173500: loss: 0.0252\n",
      "step 174000: loss: 0.0241\n",
      "step 174500: loss: 0.0243\n",
      "step 175000: loss: 0.0255\n",
      "step 175500: loss: 0.0238\n",
      "step 176000: loss: 0.0264\n",
      "step 176500: loss: 0.0236\n",
      "step 177000: loss: 0.0223\n",
      "step 177500: loss: 0.0247\n",
      "step 178000: loss: 0.0263\n",
      "step 178500: loss: 0.0245\n",
      "step 179000: loss: 0.0245\n",
      "step 179500: loss: 0.0242\n",
      "step 180000: loss: 0.0250\n",
      "step 180500: loss: 0.0284\n",
      "step 181000: loss: 0.0260\n",
      "step 181500: loss: 0.0228\n",
      "step 182000: loss: 0.0234\n",
      "step 182500: loss: 0.0230\n",
      "step 183000: loss: 0.0240\n",
      "step 183500: loss: 0.0253\n",
      "step 184000: loss: 0.0243\n",
      "step 184500: loss: 0.0231\n",
      "step 185000: loss: 0.0252\n",
      "step 185500: loss: 0.0238\n",
      "step 186000: loss: 0.0241\n",
      "step 186500: loss: 0.0228\n",
      "step 187000: loss: 0.0276\n",
      "step 187500: loss: 0.0228\n",
      "step 188000: loss: 0.0245\n",
      "step 188500: loss: 0.0222\n",
      "step 189000: loss: 0.0248\n",
      "step 189500: loss: 0.0247\n",
      "step 190000: loss: 0.0235\n",
      "step 190500: loss: 0.0242\n",
      "step 191000: loss: 0.0258\n",
      "step 191500: loss: 0.0225\n",
      "step 192000: loss: 0.0251\n",
      "step 192500: loss: 0.0244\n",
      "step 193000: loss: 0.0234\n",
      "step 193500: loss: 0.0233\n",
      "step 194000: loss: 0.0241\n",
      "step 194500: loss: 0.0230\n",
      "step 195000: loss: 0.0240\n",
      "step 195500: loss: 0.0235\n",
      "step 196000: loss: 0.0241\n",
      "step 196500: loss: 0.0247\n",
      "step 197000: loss: 0.0240\n",
      "step 197500: loss: 0.0216\n",
      "step 198000: loss: 0.0221\n",
      "step 198500: loss: 0.0255\n",
      "step 199000: loss: 0.0225\n",
      "step 199500: loss: 0.0241\n",
      "step 200000: loss: 0.0219\n",
      "step 200500: loss: 0.0225\n",
      "step 201000: loss: 0.0239\n",
      "step 201500: loss: 0.0233\n",
      "step 202000: loss: 0.0229\n",
      "step 202500: loss: 0.0227\n",
      "step 203000: loss: 0.0229\n",
      "step 203500: loss: 0.0233\n",
      "step 204000: loss: 0.0249\n",
      "step 204500: loss: 0.0238\n",
      "step 205000: loss: 0.0220\n",
      "step 205500: loss: 0.0239\n",
      "step 206000: loss: 0.0216\n",
      "step 206500: loss: 0.0238\n",
      "step 207000: loss: 0.0242\n",
      "step 207500: loss: 0.0230\n",
      "step 208000: loss: 0.0236\n",
      "step 208500: loss: 0.0223\n",
      "step 209000: loss: 0.0232\n",
      "step 209500: loss: 0.0232\n",
      "step 210000: loss: 0.0244\n",
      "step 210500: loss: 0.0223\n",
      "step 211000: loss: 0.0224\n",
      "step 211500: loss: 0.0231\n",
      "step 212000: loss: 0.0244\n",
      "step 212500: loss: 0.0250\n",
      "step 213000: loss: 0.0223\n",
      "step 213500: loss: 0.0238\n",
      "step 214000: loss: 0.0232\n",
      "step 214500: loss: 0.0253\n",
      "step 215000: loss: 0.0231\n",
      "step 215500: loss: 0.0251\n",
      "step 216000: loss: 0.0220\n",
      "step 216500: loss: 0.0247\n",
      "step 217000: loss: 0.0231\n",
      "step 217500: loss: 0.0210\n",
      "step 218000: loss: 0.0248\n",
      "step 218500: loss: 0.0247\n",
      "step 219000: loss: 0.0226\n",
      "step 219500: loss: 0.0242\n",
      "step 220000: loss: 0.0247\n",
      "step 220500: loss: 0.0245\n",
      "step 221000: loss: 0.0228\n",
      "step 221500: loss: 0.0233\n",
      "step 222000: loss: 0.0231\n",
      "step 222500: loss: 0.0220\n",
      "step 223000: loss: 0.0232\n",
      "step 223500: loss: 0.0224\n",
      "step 224000: loss: 0.0237\n",
      "step 224500: loss: 0.0218\n",
      "step 225000: loss: 0.0230\n",
      "step 225500: loss: 0.0245\n",
      "step 226000: loss: 0.0218\n",
      "step 226500: loss: 0.0234\n",
      "step 227000: loss: 0.0219\n",
      "step 227500: loss: 0.0222\n",
      "step 228000: loss: 0.0249\n",
      "step 228500: loss: 0.0248\n",
      "step 229000: loss: 0.0222\n",
      "step 229500: loss: 0.0231\n",
      "step 230000: loss: 0.0205\n",
      "step 230500: loss: 0.0227\n",
      "step 231000: loss: 0.0221\n",
      "step 231500: loss: 0.0215\n",
      "step 232000: loss: 0.0226\n",
      "step 232500: loss: 0.0242\n",
      "step 233000: loss: 0.0234\n",
      "step 233500: loss: 0.0239\n",
      "step 234000: loss: 0.0219\n",
      "step 234500: loss: 0.0245\n",
      "step 235000: loss: 0.0229\n",
      "step 235500: loss: 0.0231\n",
      "step 236000: loss: 0.0197\n",
      "step 236500: loss: 0.0207\n",
      "step 237000: loss: 0.0206\n",
      "step 237500: loss: 0.0215\n",
      "step 238000: loss: 0.0219\n",
      "step 238500: loss: 0.0239\n",
      "step 239000: loss: 0.0210\n",
      "step 239500: loss: 0.0228\n",
      "step 240000: loss: 0.0225\n",
      "step 240500: loss: 0.0221\n",
      "step 241000: loss: 0.0232\n",
      "step 241500: loss: 0.0223\n",
      "step 242000: loss: 0.0225\n",
      "step 242500: loss: 0.0217\n",
      "step 243000: loss: 0.0225\n",
      "step 243500: loss: 0.0205\n",
      "step 244000: loss: 0.0213\n",
      "step 244500: loss: 0.0221\n",
      "step 245000: loss: 0.0233\n",
      "step 245500: loss: 0.0223\n",
      "step 246000: loss: 0.0244\n",
      "step 246500: loss: 0.0243\n",
      "step 247000: loss: 0.0228\n",
      "step 247500: loss: 0.0206\n",
      "step 248000: loss: 0.0211\n",
      "step 248500: loss: 0.0229\n",
      "step 249000: loss: 0.0217\n",
      "step 249500: loss: 0.0223\n",
      "step 250000: loss: 0.0231\n",
      "step 250500: loss: 0.0210\n",
      "step 251000: loss: 0.0218\n",
      "step 251500: loss: 0.0221\n",
      "step 252000: loss: 0.0225\n",
      "step 252500: loss: 0.0215\n",
      "step 253000: loss: 0.0241\n",
      "step 253500: loss: 0.0215\n",
      "step 254000: loss: 0.0204\n",
      "step 254500: loss: 0.0228\n",
      "step 255000: loss: 0.0224\n",
      "step 255500: loss: 0.0228\n",
      "step 256000: loss: 0.0220\n",
      "step 256500: loss: 0.0212\n",
      "step 257000: loss: 0.0218\n",
      "step 257500: loss: 0.0213\n",
      "step 258000: loss: 0.0221\n",
      "step 258500: loss: 0.0205\n",
      "step 259000: loss: 0.0210\n",
      "step 259500: loss: 0.0206\n",
      "step 260000: loss: 0.0239\n",
      "step 260500: loss: 0.0233\n",
      "step 261000: loss: 0.0240\n",
      "step 261500: loss: 0.0195\n",
      "step 262000: loss: 0.0223\n",
      "step 262500: loss: 0.0214\n",
      "step 263000: loss: 0.0241\n",
      "step 263500: loss: 0.0198\n",
      "step 264000: loss: 0.0226\n",
      "step 264500: loss: 0.0212\n",
      "step 265000: loss: 0.0227\n",
      "step 265500: loss: 0.0208\n",
      "step 266000: loss: 0.0213\n",
      "step 266500: loss: 0.0203\n",
      "step 267000: loss: 0.0223\n",
      "step 267500: loss: 0.0233\n",
      "step 268000: loss: 0.0233\n",
      "step 268500: loss: 0.0204\n",
      "step 269000: loss: 0.0210\n",
      "step 269500: loss: 0.0223\n",
      "step 270000: loss: 0.0217\n",
      "step 270500: loss: 0.0206\n",
      "step 271000: loss: 0.0203\n",
      "step 271500: loss: 0.0219\n",
      "step 272000: loss: 0.0223\n",
      "step 272500: loss: 0.0214\n",
      "step 273000: loss: 0.0203\n",
      "step 273500: loss: 0.0209\n",
      "step 274000: loss: 0.0203\n",
      "step 274500: loss: 0.0214\n",
      "step 275000: loss: 0.0218\n",
      "step 275500: loss: 0.0206\n",
      "step 276000: loss: 0.0222\n",
      "step 276500: loss: 0.0221\n",
      "step 277000: loss: 0.0217\n",
      "step 277500: loss: 0.0188\n",
      "step 278000: loss: 0.0206\n",
      "step 278500: loss: 0.0208\n",
      "step 279000: loss: 0.0192\n",
      "step 279500: loss: 0.0198\n",
      "step 280000: loss: 0.0197\n",
      "step 280500: loss: 0.0225\n",
      "step 281000: loss: 0.0199\n",
      "step 281500: loss: 0.0212\n",
      "step 282000: loss: 0.0218\n",
      "step 282500: loss: 0.0223\n",
      "step 283000: loss: 0.0211\n",
      "step 283500: loss: 0.0211\n",
      "step 284000: loss: 0.0221\n",
      "step 284500: loss: 0.0223\n",
      "step 285000: loss: 0.0217\n",
      "step 285500: loss: 0.0211\n",
      "step 286000: loss: 0.0185\n",
      "step 286500: loss: 0.0215\n",
      "step 287000: loss: 0.0205\n",
      "step 287500: loss: 0.0225\n",
      "step 288000: loss: 0.0228\n",
      "step 288500: loss: 0.0211\n",
      "step 289000: loss: 0.0213\n",
      "step 289500: loss: 0.0210\n",
      "step 290000: loss: 0.0219\n",
      "step 290500: loss: 0.0233\n",
      "step 291000: loss: 0.0199\n",
      "step 291500: loss: 0.0217\n",
      "step 292000: loss: 0.0221\n",
      "step 292500: loss: 0.0197\n",
      "step 293000: loss: 0.0222\n",
      "step 293500: loss: 0.0209\n",
      "step 294000: loss: 0.0214\n",
      "step 294500: loss: 0.0210\n",
      "step 295000: loss: 0.0223\n",
      "step 295500: loss: 0.0221\n",
      "step 296000: loss: 0.0215\n",
      "step 296500: loss: 0.0191\n",
      "step 297000: loss: 0.0210\n",
      "step 297500: loss: 0.0218\n",
      "step 298000: loss: 0.0203\n",
      "step 298500: loss: 0.0208\n",
      "step 299000: loss: 0.0188\n",
      "step 299500: loss: 0.0221\n",
      "step 300000: loss: 0.0222\n",
      "\tstep 300000: saved model\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "running_loss = None\n",
    "# generic train loop\n",
    "for global_step in range(global_step, total_steps+global_step+1):\n",
    "    \n",
    "    # forward\n",
    "    np_psi0 = next_batch(D_side)\n",
    "    real_psi0 = Variable(torch.Tensor(np_psi0))\n",
    "    psi0_hat = forward(real_psi0, model).t()\n",
    "\n",
    "    # backward\n",
    "#     loss = .5*torch.sum(cost_func(psi0_hat, real_psi0)**2) / batch_size\n",
    "    loss = .5*torch.sum((psi0_hat - real_psi0)**2) / batch_size\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    running_loss = loss.data.numpy()[0] if running_loss is None else .99*running_loss + (1-.99)*loss.data.numpy()[0]\n",
    "\n",
    "    # ======== DISPLAY PROGRESS ======== #\n",
    "    if global_step % print_every == 0:\n",
    "        print('step {}: loss: {:.4f}'.format(global_step, running_loss))\n",
    "    if global_step in checkpoint_steps:\n",
    "        print('\\tstep {}: saved model'.format(global_step))\n",
    "        torch.save({'state_dict': model.state_dict(),\n",
    "                   'global_step': global_step}\n",
    "                   , save_dir + '/model.{}.tar'.format(global_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model: psi2psi-sigmoid_models/model.1.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.10.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.100.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.1000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.10000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.100000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.128000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.16000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.2000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.250.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.30.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.300.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.3000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.30000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.300000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.4000.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.500.tar\n",
      "loaded model: psi2psi-sigmoid_models/model.64000.tar\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "load_was_success = True # yes, I'm being optimistic\n",
    "model_zoo = []\n",
    "paths = glob.glob(save_dir + '/*.tar')\n",
    "try:\n",
    "    for s in paths:\n",
    "        checkpoint = torch.load(s)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        global_step = checkpoint['global_step']\n",
    "        model_zoo.append((global_step, copy.deepcopy(model)))\n",
    "        print(\"loaded model: {}\".format(s))\n",
    "    model_zoo = sorted(model_zoo, key=lambda tup: tup[0])\n",
    "    global_step, model = model_zoo[-1]\n",
    "except:\n",
    "    print(\"no saved model to load.\") ; model_zoo = []\n",
    "    load_was_success = False\n",
    "else:\n",
    "    if len(paths) is 0: print(\"no saved model to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean percent error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error: 0.0390 \n",
      "mean percent error: 3.8979%\n"
     ]
    }
   ],
   "source": [
    "mpe = 0 ; me = 0\n",
    "k = 1000\n",
    "for i in range(k):\n",
    "    np_psi0 = next_batch(D_side)\n",
    "    real_psi0 = Variable(torch.Tensor(np_psi0))\n",
    "    psi0_hat = forward(real_psi0, model).t()\n",
    "    np_psi0_hat = psi0_hat.data.numpy()\n",
    "    me += (1./k)*np.mean(np.abs(np_psi0 - np_psi0_hat))\n",
    "    mpe += (1./k)*np.mean(np.abs(np_psi0 - np_psi0_hat))/1.*100\n",
    "print(\"mean error: {:.4f} \\nmean percent error: {:.4f}%\".format(me, mpe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect autoencoded MPS for GHZ state\n",
    "The closer the two are, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70710678  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.70710678]\n",
      "[ 0.63647085  0.09022165  0.06984287  0.02878165  0.04598853  0.00858638\n",
      "  0.03570671  0.05689332  0.02266762  0.02760242  0.00550297  0.06086965\n",
      "  0.00921897  0.0362754   0.03676523  0.62731451]\n",
      "[[ 0.82692921]]\n",
      "mean error: 0.0548 \n",
      "mean percent error: 5.4770%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAADeCAYAAADSK2E5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHWWd7/HPNwm7yBZFIFyDGhkjCoSoKHcch2UM4gRn\nRC+MOqK4jDO4AHfmgguKeh3UEQevqBNZR1FZRI0jEgRkmFFQkihbEImIkMgWNpE1SX/vH1UNJ53u\n9Emq+pyuru/79apXn6rzVNXvOel0//p5nnoe2SYiIiKiLSb1O4CIiIiIXkryExEREa2S5CciIiJa\nJclPREREtEqSn4iIiGiVJD8RERHRKkl+IiIiolWS/ERERESrJPmJiIiIVpnS7wAiIiKif17951v4\n3vtWV7rGomsfX2B7Tk0hjbkkPxERES224r7V/GzBtErX2GiH30ytKZyeSPITERHRama1B/odRE8l\n+YmIiGgxA6uo1u3VNEl+IiIiWsyY1Xa/w+ipJD8REREtN0CSn4iIiGgJAytp15ifzPMTERHRYgZW\n25W2bkiaI+kmSUslHTvM+/9D0o8l/ULStZJeU3ddByX5iYiIaLmBittoJE0GTgEOBGYCh0maOaTY\nh4Fzbe8JHAp8qVqtRpZur4iIiBYzZvXYj/l5KbDU9i0Akr4FHAwsWSMUeHr5eivg92MVTJKfiAaS\n9DrgObZP6ncsEdFsNqysnvtMlbSwY3+e7Xkd+zsBt3fsLwNeNuQaHwMulvReYAtg/8pRjSDJT0Qz\nvY7iB0OSn4ioSKxGVS+ywvbsitc4DDjT9uckvRz4mqTd7PpnYEzyEzHBSdrE9uP9jiMixicDA2P/\npPtyYOeO/WnlsU5HAHMAbF8paVNgKnB33cFkwHNEw0g6E3grsJMkl9ut5XsfK/d3k7RA0h+BcyWd\nOVhmyLUul3T5kGO7S5ov6X5Jj0r6iaQ/7SKup0sakPTucv9t5f6W5f6lki6sWP2IGAOry9afDd26\ncDUwQ9IukjamGNA8f0iZ24D9ACS9ANgUuKfGaj4pLT8RzfMJ4BnAS4C55bGhLTvfA04DPk3xMMbh\n3VxY0izgv4BfAO8EHgH+DrhE0itsL1rH6XsCAhaX+7OAm20/1PH+mD29EREbxsBKj21biO1Vko4E\nFgCTgdNt3yDp48BC2/OBY4CvSjqqDOtwe2ymnk7yE9Ewtn8j6R7gCdtXjVDsC7ZPHtyRdHiXl/8s\nxV9f+9p+ojx3AXA98BGKsUYjmQWsAq7t2F9cXmMXYBueSowiYpww1DHmZ/T72BcCFw45dnzH6yXA\nPmMeCOn2ipiovrO+J0jaDPgz4DxgQNIUSVMoWnMuAV45yiVmAUtsPy5pErA7a7YCQZKfiHHHiNVM\nqrQ1TVp+IiamOzbgnG0pmqM/Um5rkTRpHU9ezAJ+Xr7eleJR1cFkZ0/gPtu3bkBcETHGBjz2LT/j\nSZKfiIlpaD/5Y8DGw5TbDri3fP0AxfigU4B/H/aiIyQ+ZUvP84Fzy0NDW3oOAH7aTeAR0VtGPOHJ\n/Q6jp5L8RDTT48Bm61H+d8D2kp5h+x4ASc+laKH5KYDthyX9F2V31XrOrTH4Z+OO5ddZwK227y/X\n53kp8Pr1uF5E9IiBgQZ2XVWR5CeimZYA20p6D7AQeMz2desofx7FU2Jfl3QSxdwZxwErhpQ7GrgC\nWCDpNIrus6kUycxk22stRghge7WkbwNHlGv47A08KumrwN8CX7F9wQbWNSLGWC8GPI8nSX4imulU\nigTjU8DWFC0700cqbHuppEOATwLfBX5Nkeh8cEi5xZJeAnwU+ALF+jr3UHRffWWUmN4KLAIOAV5I\n8dQYwKtsX7kedYuIHrLFypZ1e2mMHqGPiJYqu9OWAgfavqjf8UTEus140WY+ef5zK13joOfcsKiG\n5S16Ji0/EVG3PNYe0Shi9RhPcjjeVEp+JG0LnEPR3H4r8Ebb9w9TbjUwOB7hNttzh5aJiAljFrDc\ndu3r8URE/do44LlqbY8FLrU9A7i03B/Oo7b3KLckPhETmO3jbE/rdxwR0Z3BR92rbE1TtdvrYOBV\n5euzgMuB/1PxmhEREdFDA+n2Wi/b2x6cSfZOYPsRym0qaSHFuj8n2v7ucIUkvQt4F8Amm0/aa4dd\n1mcak2ru/e3Te3aviIhohu12+UNP73frDQ+vsP2MXt6zWNsryc8aJF0CPGuYtz7UuWPbkkZ6dOzZ\ntpdLeg5wmaTrbP9maCHb84B5ALvs9jR/9IIXjVqBunzjTa/u2b0iIqIZ/ubsBT2939t2vep3Pb0h\n5dpeWd5iTbb3H+k9SXdJ2sH2HZJ2AIYd4Gh7efn1FkmXU6zzs1byExEREb1lw0q36+Hvqu1c8ykm\nNqP8+r2hBSRtI2mT8vVUiuXql1S8b0RERNRCDFTcmqZqqncicK6kIyhmmH0jgKTZwN/ZfgfwAuDf\nJA1QJFsn2k7yExERMQ4YMs/P+rB9L7DfMMcXAu8oX/8U6N3gnYiIiOiaad/yFu3q5IuIiIi15Gmv\niIiIaA2TeX4iIiKiVcTqBg5ariLJT0RERIsZWjfmp5Z2LklzJN0kaamktdb3krSJpHPK938maXod\n942IiIhqbDHgSZW2pqkcsaTJwCnAgcBM4DBJM4cUOwK43/bzgM8Dn65634iIiKjHak+qtDVNHRG/\nFFhq+xbbTwDfoljwtNPBFAufApwP7CepXR2MERER45AhkxxugJ2A2zv2lwEvG6mM7VWSHgS2A1Z0\nFupc2HS7HTeuIbSIiIhYFyNWDrRrzM+4GvA8dGHTPocTERHRCpnnZ/0tB3bu2J9WHhuuzDJJU4Ct\ngHtruHdERERUYMRAy1Z1ryPVuxqYIWkXSRsDh1IseNqpcwHUQ4DLbKdlJyIiYhwYYFKlrWkqt/yU\nY3iOBBYAk4HTbd8g6ePAQtvzgdOAr0laCtxHkSBFREREn9mwcqB5CUwVtYz5sX0hcOGQY8d3vH4M\neEMd94qIiIj6FN1eSX4iIiKiRdq2vEW7Ur2IiIhYgxGrBiZX2rox2moQZZk3Sloi6QZJ36i1oh3S\n8hMREdFyYz1RYcdqEAdQzAd4taT5tpd0lJkBHAfsY/t+Sc8cq3iS/ERERLSYDavH/lH3J1eDAJA0\nuBrEko4y7wROsX1/EZfvHqtgkvxERES0XA0DnqdKWtixP6+cuHhQN6tBPB9A0k8onh7/mO2LqgY2\nnFqSH0lzgJMpgj3V9olD3j8c+CxPTX74Rdun1nHviIiI2HBGrKqe/KywPbviNaYAM4BXUUyYfIWk\nF9l+oGpww92okm768Urn2D6y6v0iIiKiPoZezPDczWoQy4Cf2V4J/FbSrymSoavrDqZXq7pHRETE\nODXgSZW2LnSzGsR3KVp9kDSVohvslvpq+ZRereoO8HpJrwR+DRxl+/ahBTpXdQf++LZdr7ppA+KZ\nypDV4rtz1Qbcqi82sH6Nkfo120Su30SuG6R+w/rRrmMQybo9u+d39Niv7dXlahALgL+QtARYDfyj\n7TFZB7RXA56/D3zT9uOS3g2cBew7tFDnqu4bStLCGvodx63Ur9lSv+aayHWD1K/NDHWM+Rn9PqOv\nBmHg6HIbUz1Z1X1I5nYq8Jka7hsREREV9WjMz7hSR/LzZD8eRdJzKPA3nQUk7WD7jnJ3LnBjDfeN\niIiIGiT5WU9d9uO9T9JcYBXFqu6HV73vOlTqNmuA1K/ZUr/mmsh1g9SvtWp61L1RVHSxRURERBtt\ntev23nveYZWucfGrTl7UpDFVmeE5IiKixTLmJyIiIlqnbcnPhOrkkzRH0k2Slko6tt/x1EnSzpJ+\nLGmJpBskvb/fMdVN0mRJv5D0H/2OpW6StpZ0vqRfSbpR0sv7HVOdJB1Vfl9eL+mbkjbtd0xVSDpd\n0t2Sru84tq2kH0m6ufy6TT9jrGKE+n22/P68VtJ3JG3dzxirGK5+He8dI8nlJHpBMeZn9cCkSlvT\nNC/iEXQss3EgMBM4TNLM/kZVq1XAMbZnAnsD/zDB6gfwfibuk4AnAxfZ/hNgdyZQPSXtBLwPmG17\nN4oHHw7tb1SVnQnMGXLsWOBS2zOAS8v9pjqTtev3I2A32y+mmIz2uF4HVaMzWbt+SNoZ+Avgtl4H\nNN4NoEpb00yY5IcJvsyG7TtsLy5fP0Txy3On/kZVH0nTgIMo5oGaUCRtBbwSOA3A9hNjsVBfn00B\nNpM0Bdgc+H2f46nE9hUUT6Z2OphiglbKr6/raVA1Gq5+ti+2varcvYpizrZGGuHfD+DzwD9RDHOJ\nkl10e1XZmmYiJT/DLbMxYZKDTpKmA3sCP+tvJLX6V4ofSgP9DmQM7ALcA5xRduudKmmLfgdVF9vL\ngX+h+Gv6DuBB2xf3N6oxsX3HfGV3Atv3M5gx9nbgh/0Ook6SDgaW276m37GMR7YqbU0zkZKfVpD0\nNODbwAds/6Hf8dRB0muBu20v6ncsY2QKMAv4su09gYdpdpfJGsqxLwdTJHk7AltIenN/oxpb5TT8\nE7L1QNKHKLrZz+53LHWRtDnwQeD40cq2U8b8NNmoy2w0naSNKBKfs21f0O94arQPMFfSrRTdlftK\n+np/Q6rVMmCZ7cGWuvMpkqGJYn/gt7bvsb0SuAB4RZ9jGgt3SdoBilnrgbv7HE/tJB0OvBZ4kyfW\nJHDPpUjOryl/zkwDFkt6Vl+jGicGH3VPt1czPbnMhqSNKQZczu9zTLWRJIoxIzfaPqnf8dTJ9nG2\np9meTvHvdpntCdNyYPtO4HZJg+tD7wcs6WNIdbsN2FvS5uX36X5MoAHdHeYDby1fvxX4Xh9jqZ2k\nORRdz3NtP9LveOpk+zrbz7Q9vfw5swyYVf7fDBfjfqpsTTNhkp9yoN7gMhs3AufavqG/UdVqH+At\nFK0ivyy31/Q7qOjae4GzJV0L7AF8qs/x1KZs0TofWAxcR/FzpdFLCUj6JnAlsKukZZKOAE4EDpB0\nM0Vr14n9jLGKEer3RWBL4Eflz5ev9DXICkaoX4zAwGpPqrQ1TZa3iIiIaLHNZ+zo5/9rtfzwmtd+\nMstbRERERHO0rR0kyU9ERETLNfFx9SqS/ERERLSYTSMfV68iyU9ERETLpdsrIiIiWqVt3V7taueK\niIiINZhqS1v0I3GS9HxJl0q6vtx/saQPd3t+kp+IiIg2a+bCpl8FjgNWAti+lmKS3K6k2ysiIqLt\nmjfmZ3PbPy8mlX/Sqm5PTvITERHRcg0c87NC0nMp0zZJhwB3dHtykp+IiIiWa+DTXv9AsYzOn0ha\nDvwW6HpNyCQ/ERERLWaDGzbPj+1bgP0lbQFMsv3Q+pyf5CciIqLlmtLyI+noEY4DYPukbq6T5Cci\nIqLtGpL8AFvWcZEkPxEREa0mPNCMAc+2T6jjOkl+IiIi2szNe9pL0qbAEcALgU0Hj9t+ezfnN2uE\nU0RERNTPFbfe+xrwLODVwH8C04CuBz0n+YmIiGg9Vdy6uIM0R9JNkpZKOnYd5V4vyZJmr+Nyz7P9\nEeBh22cBBwEv6yoQkvxERETEQMVtFJImA6cABwIzgcMkzRym3JbA+4GfjXLJleXXByTtBmwFPHP0\nSApJfiIiItrMgFVtG91LgaW2b7H9BPAt4OBhyn0C+DTw2CjXmydpG+DDwHxgCfCZbqucAc8REREt\nV8M8P1MlLezYn2d7Xsf+TsDtHfvLGNJNJWkWsLPtH0j6x3XdzPap5csrgOesb7BJfiIiItquevKz\nwva6xuisk6RJwEnA4V2W/xTwGdsPlPvbAMfY/nA356fbKyIiouU0oEpbF5YDO3fsTyuPDdoS2A24\nXNKtwN7A/HUMej5wMPEBsH0/8Jpu65vkJyIios2qPubeXavR1cAMSbtI2hg4lGKsThGC/aDtqban\n254OXAXMtb1w+MsxWdImgzuSNgM2GaHsWtLtFRER0WpdD1reYLZXSToSWABMBk63fYOkjwMLbc9f\n9xXWcjZwqaQzyv23AWd1e3KSn4iIiLbr4nH1qmxfCFw45NjxI5R91SjX+rSka4D9y0OfsL2g21iS\n/ERERLRdcxY2BUDSFsDFti+StCuwq6SNbK8c7VzImJ+IiIh26808P3W7AthU0k7ARcBbgDO7PTnJ\nT0RERMvJ1ba+hGw/Avw18GXbb6BY5LQrSX4iIiLarnkLm0rSy4E3AT8oj03u9uSM+YmIiGi5PrXe\nVPF+4DjgO+VTY88BftztyUl+IiIi2q4/43Y2mO0rKMb9DO7fAryv2/OT/ERERLRZ/7qu+ibJT0RE\nRMupB/P8jCcZ8BwREdF2DRrwLGmypKOqXCPJT0RERNs1KPmxvRo4rMo10u0VERHRYn2cq6eKn0j6\nInAO8PDgQduLuzk5yU9ERETbDTTraS9gj/LrxzuOGdi3m5OT/ERERLRc01p+bP95lfMz5iciIqLt\nGjTmB0DSVpJOkrSw3D4naatuz0/yExER0WYuHnWvsvXB6cBDwBvL7Q/AGd2enG6viIiItmtYtxfw\nXNuv79g/QdIvuz05LT8REREt18BV3R+V9D+fjF/aB3i025PT8hMRERFN8x7grHKcj4D7gMO7PTnJ\nT0RERJu5ectb2P4lsLukp5f7f1if85P8REREtF1DxvxIOnqE4wDYPqmb6yT5iYiIaLuGJD/AlnVc\nJMlPREREi4nmTHJo+4Q6rpOnvSIiItqsgfP8SJom6TuS7i63b0ua1u35SX4iIiLarmEzPFNMaDgf\n2LHcvs96THKY5CciIqLtmpf8PMP2GbZXlduZwDO6PTnJT0RERMs1rdsLuFfSmyVNLrc3A/d2e3KS\nn4iIiDar2urTn5aft1Os6XUncAdwCPC2bk/O014REREt15SnvQbZ/h0wd0PPT8tPRERE2zWs5UfS\nWZK27tjfRtLp3Z6flp+IiIiWa9ryFsCLbT8wuGP7fkl7dntyWn4iIiLarJljfiZJ2mZwR9K2rEeD\nTlp+IiIiWkzl1jCfA66UdF65/wbg/3Z7clp+IhpM0utGWuivyfeXdLmky+u+bkSMoActP5LmSLpJ\n0lJJxw7z/tGSlki6VtKlkp49Yrj2vwN/DdxVbn9t+2td1jYtPxEN9zpgf6CrlYwn4P0jogZjPeZH\n0mTgFOAAYBlwtaT5tpd0FPsFMNv2I5LeA3wG+F8jXbM8d8lI769LWn6i1SRt0u8YeqVNdY2I9TT2\nLT8vBZbavsX2E8C3gIPXCMH+se1Hyt2rgK7X6lpfSX6iNSR9TJIl7SZpgaQ/AueW7+0uab6k+yU9\nKuknkv50mGvsXi6md29Z7iZJxw0pM0fSleX7D0r6rqRdR4hlhqQfSPqjpN9JOl7SpI5yz+9YvO8x\nSbdJOk/SFElnAm8FdiqvZUm3dlHXMwfLDYlpra6mddV3Xfdfz8/0UEm/kvS4pBsk/dXI/4prnPd0\nSQOS3l3uv63c37Lcv1TShd1cK6LVXMzzU2UDpkpa2LG9a8hddgJu79hfVh4byRHAD2utZ4d0e0Ub\nfQ84Dfg0MCBpFvBfFE2u7wQeAf4OuETSK2wvApD0UuByYClwFMV/3hnAiwcvLGkO8APgMorm2qcB\nHwf+W9IetpcPieU7FIvxfR74S+AEih8Qgwv0/QC4H3gPsILih8VrKP5w+QTFWjYv4anJvh5fV13X\n50Pqor4j3n89PtP9gW+U9TymvN7JwEbATaOEuCfFOM3F5f4s4GbbD3W8/6X1qXNEW9XQ7bXC9uwa\nQqFcqmI28Gd1XG84SX6ijb5g++TBHUmXArcB+5bNsUhaAFwPfIRiXAvAv1CsHbN3R9PsZUOu/Ung\nFuBA26vKa10J/Jril/vQwcGfsz2Y6FwiaV/gMOAMSVOB5wEH257fcc43yq+/kXQP8ITtq7qp63pa\nZ31tr+v+n6W7z/QE4FcUdRwoy/0KuJLRk59ZwCrg2o79xeU1dgG24anEKCLWZewfV18O7NyxP608\ntobyD6IPAX9me+gfc7VJt1e00XcGX0jajOKvi/MoWoGmSJpC0aJwCfDKstzmwD7A2R2JwBokbUHx\nC/icwcQHwPZvgZ8w/F8xPxiyfz3wP8rX91IkUidKeqekGetbUTrquj66qe86zu32M51M0Wp0/mDi\nA1AmUrd2catZwBLbj5ddhbuzZisQPJUMzSq75b7ReQFJXymPzy3LPCLpl5JulLRI0m5luY0lfVzS\nYknXSPqNpK4fq40Y72ro9hrN1cAMSbtI2hg4FOj8ow4VkxT+GzDX9t1117FTkp9oozs6Xm8LTKZo\njVg5ZDsS2Kb8xboNxf+XZeu47jYUv+DvGOa9O8t7DXXfkP3HgU0BbJviyYiFwD8Dv5Z0i4qnILo1\nXCzd6Ka+I+n2M51K0b111zDXGO7YUE+29AC7Alt07O8J3Gf71nJ/L4rP8UWDJ5c/aPcGngAWlWUu\ns72H7RcAPwc+Whb/LMVfrXvb3h14IXB2FzFGjH89mOSw/IPwSGABcCNwru0byj8qBrvNP0sxVOC8\n8o+Q+SNcrrJ0e0Ubdf5XfYBiLMwpwL8PW9gekHR/WW5dA/TuL6/9rGHeexZrJzqjB2rfAvytJFG0\nbBwJfEnSrba7GQw43I+lx4CNhzm+HUVrExR1Ga2+I+n2M11BkRBtP0yR7YHfjXSDMnl6PuUgboa0\n9FAkjT/tOGU2RSvY+yRtRNFd9kVgHnC87eWSZgPXdZxza0dsrwU+MtiFZ/sxNvAR24jxRvRmeQvb\nFwIXDjl2fMfr/cc+ikJafqLVbD9MMTB3d2Cx7YVDt7LcI8B/A28uu3VGutYi4A1llw4AKibqegXF\n4OENjdO2f8lTY4Z2K78+Dgwbzzr8Dthe0jM6YnwuRevJ4P1Gre9I91+Pz3Q1RVP4IVrzCbeXAdNH\nqcPghLQ7ll9nAbeW6/u8huKx2jM6yu9F8W9zA/AC4C0Uyc0j5fHBMteVMUwD3s5TydX3KcZh/VDS\nUZKeOUp8Ec3SvOUtKknLT0SRUFwBLJB0GkVX0VSKX6iTbQ/ORPq/gf+kmFL9cxRdQs8B9rD93rLM\nRyjG8fyHpC9RNOGeADxIMR171yS9mOLJp3MonriaDBxO0WoxOPB4CbBt2RW2EHjM9nVrX20N51E8\nqfV1SSeVdT2O4mmyTt3Ud6T7d/uZfhS4GPiupH+jeNrrBIpuwhHZXi3p28ARZaK5N/CopK8Cfwt8\nxfYF5ee4MUV31yKKp8/2KeN7FXAssKijzEckHQM8DHzS9rfK+31A0inAqyme4jtO0q627x/ls45o\nBLmBGUwFSX6i9WwvlvQSil/EXwC2Au6h6EL5Ske5qyXtQ/Ho+v8DNqFoRTmjo8xFkg4qr3UuxXiS\ny4F/sv379QztToonpo6meDLiMYqWidcOPioOnErxi/9TwNZlPNNHqe9SSYdQPJn2XYon0Y4GPjik\n3Kj1Hen+6/GZXiLpTcDHgAsokrwPAO/v4vN5K0VCcwjFGJzbyuOvsn1lR7kXAXfZXiHpFxTdcZ8u\nu7pmUcwi+yKKVqCZ5Vir4T63m4GbywTrUeDZFN2DEc3W0NabKjTC//OIiEYou+yWUkwvcNEw778b\nmGP7ryTtCLyZokVtFfAHiu6+g4BDbB8wzPkHAVfYfqgce/X3FMnZC22vHKt6RfTKFlN39sy/PKrS\nNRaeecyiuub56YW0/ERE0w0d7DzUXoPvla1vnwGQ9ELgj7aXSdqLYvzRcA4CTpb0KLCaovVt/yQ+\nMZF0+bj6hFEp+ZG0LcV4hOkUgwffOFwfuKTBHxgAt9meO7RMRMQGmgUsH2leENtDp9kfPH4D5dNc\nI5Up3/v7OoKMGNdalvxUfdrrWOBS2zOAS8v94Txazp2xRxKfiKiT7eNsj9kCiBETXj1rezVK1eTn\nYOCs8vVZPDVlfURERDTA4Dw/VbamqTrmZ3vbgzPI3snwk5UBbCppIcUAwxNtf3e4QuUqsO8C2Giz\nyXttO/3pFcPr3sO/37xn9wJ63sSogV7fUKOXqdPqHtevhzNkucefZe+/V3p7O3pcP0/u7XRqmsD/\nF/ph050f6+n97rnxvhW2nzF6yZq17OGnUZMfSZcw/Iy1H+rcsW1pxMavZ5ePlT4HuEzSdbZ/M7SQ\n7XkUM67yrJnb+k3f6Nlkj/z8oy/p2b0AJq3s7TfaRg/1dmzmwMa9/Yk45Y+9rd/qTXv3rECvP8vJ\nj64avVCdepzcTXq8t/V7YutNenq/jR98oqf36+X/hX54weev7+n9TtnrmyPObD6Wmth1VcWo37Xr\nmm5a0l2SdrB9h6QdgJEGHC4vv94i6XKKdXfWSn4iIiKixwxa3e8geqvqn5TzKSYao/z6vaEFJG0j\naZPy9VSK2VWzJk5ERMR40bLlLaomPycCB0i6Gdi/3EfSbEmnlmVeACyUdA3wY4oxP0l+IiIixom2\nPe1VqbPW9r3AfsMcXwi8o3z9U4qp4yMiImK8MRnwHBEREe3SxMfVq0jyExER0WKimV1XVST5iYiI\naDM73V4RERHRLmn5iYiIiFZp25ifWqaOlTRH0k2Slkpaa3FTSZtIOqd8/2eSptdx34iIiKjIFMu+\nVNkapnLyI2kycApwIDATOEzSzCHFjgDut/084PPAp6veNyIiImqSSQ7X20uBpbZvsf0E8C2K1d47\nda7+fj6wn9TrlS8jIiJiOBpwpa1p6kh+dgJu79hfVh4btoztVcCDwHZDLyTpXZIWSlr4yAOP1xBa\nREREjKZtMzz3drnoUdieZ3u27dmb93gl5IiIiFaq2uXVwOSnjqe9lgM7d+xPK48NV2aZpCnAVsC9\nNdw7IiIiKigmOWxgBlNBHS0/VwMzJO0iaWPgUIrV3jt1rv5+CHCZ3bJPOiIiYpzSalfamqZyy4/t\nVZKOBBYAk4HTbd8g6ePAQtvzgdOAr0laCtxHkSBFREREvzW066qKWiY5tH0hcOGQY8d3vH4MeEMd\n94qIiIg6ZXmLiIiIaJkmPrFVRZKfiIiINjONHLdTRZKfiIiItmtZt9e4mucnIiIi+qAH8/yMp3VA\nk/xERES0nOxK26jXH2frgPZqVffDJd0j6Zfl9o467hsREREVGVjtatvoxtU6oJXH/HRkcwdQrOt1\ntaT5tpefSdxoAAAF9klEQVQMKXqO7SOr3i8iIiLqI7prvRnFVEkLO/bn2Z7XsT/cOqAvG3KNNdYB\nlTS4DuiKqsENVceA5yezOQBJg9nc0OQnIiIixqPqyc8K27PrCKUX6kh+usnmAF4v6ZXAr4GjbN8+\ntICkdwHvKnf/eNKe5920AfFMZYOyxPM24FZ9sYH1a4zUr9kmcv0mct0g9RvWZXuNQSTr9uye33Gw\n22tsjat1QHv1qPv3gW/aflzSuyn69PYdWqhsIps39Pj6kLSwSdnn+kr9mi31a66JXDdI/dquBwub\nPrkOKEWScyjwN0PKDK4DeiVjvA5oHQOeR83mbN9r+/Fy91Sg97l0REREDM+uto16ea8CBtcBvRE4\nd3AdUElzy2KnAduV64AeDaz1AFVd6mj5GTWbk7SD7TvK3bkUFY+IiIi+683aXuNpHdBerer+vjKz\nW0WxqvvhVe+7DpW6zRog9Wu21K+5JnLdIPVrr96M+RlXNEbdaREREdEAW222g1+xy9sqXeOiG/95\nUZPGVGVtr4iIiLZrWUNIkp+IiIg2MzDQruRnQq3tNdoyG00maWdJP5a0RNINkt7f75jqJmmypF9I\n+o9+x1I3SVtLOl/SryTdKOnl/Y6pTpKOKr8vr5f0TUmb9jumKiSdLuluSdd3HNtW0o8k3Vx+3aaf\nMVYxQv0+W35/XivpO5K27meMVQxXv473jpFkSVP7Edv4ZBgYqLY1zIRJfrpcNK3JVgHH2J4J7A38\nwwSrH8D7mbhPAp4MXGT7T4DdmUD1lLQT8D5gtu3dKB58OLS/UVV2JjBnyLFjgUttzwAuZQwfw+2B\nM1m7fj8CdrP9YorJaI/rdVA1OpO164eknYG/AG7rdUDj3hg/6j7eTJjkh+4WTWss23fYXly+foji\nl+dO/Y2qPpKmAQdRzAM1oUjaCnglxRwW2H7C9gP9jap2U4DNyllZNwd+3+d4KrF9BcWTqZ06F108\nC3hdT4Oq0XD1s31xORcLwFUUc7Y10gj/flCsFP5PFB09MWiw26vK1jATKfkZbpmNCZMcdJI0HdgT\n+Fl/I6nVv1L8UGpe++nodgHuAc4ou/VOlbRFv4Oqi+3lwL9Q/DV9B/Cg7Yv7G9WY2L5jvrI7ge37\nGcwYezvww34HUSdJBwPLbV/T71jGH8PA6mpbw0yk5KcVJD0N+DbwAdt/6Hc8dZD0WuBu24v6HcsY\nmQLMAr5se0/gYZrdZbKGcuzLwRRJ3o7AFpLe3N+oxlY55X7z/tztgqQPUXSzn93vWOoiaXPgg8Dx\no5VtpbT8NFo3i6Y1mqSNKBKfs21f0O94arQPMFfSrRTdlftK+np/Q6rVMmCZ7cGWuvMpkqGJYn/g\nt7bvsb0SuAB4RZ9jGgt3SdoBilnrgbv7HE/tJB0OvBZ401itqdQnz6VIzq8pf85MAxZLelZfoxpP\nMuansZ5cZkPSxhQDLuf3OabaSBLFmJEbbZ/U73jqZPs429NsT6f4d7vM9oRpObB9J3C7pF3LQ/sB\nS/oYUt1uA/aWtHn5fbofE2hAd4fBRRcpv36vj7HUTtIciq7nubYf6Xc8dbJ9ne1n2p5e/pxZBswq\n/28GJPlpqpEWTetvVLXaB3gLRavIL8vtNf0OKrr2XuBsSdcCewCf6nM8tSlbtM4HFgPXUfxcafRS\nApK+SbGy9K6Slkk6AjgROEDSzRStXSf2M8YqRqjfF4EtgR+VP1++0tcgKxihfjESG1avrrY1TJa3\niIiIaLGtNnqmX7HdIZWucdFdX87yFhEREdEgLWsISfITERHRas18YquKJD8RERFtZnADx+1UkeQn\nIiKi7dLtFREREa1hN3Jx0iqS/ERERLRcur0iIiKiRZo5UWEVSX4iIiLabHBtrxZJ8hMREdF2zpif\niIiIaAnbGfMTERER7eKWdXtlba+IiIgWk3QRMLXiZVbYnlNHPL2Q5CciIiJaZVK/A4iIiIjopSQ/\nERER0SpJfiIiIqJVkvxEREREqyT5iYiIiFZJ8hMRERGtkuQnIiIiWiXJT0RERLRKkp+IiIholf8P\nCNBMiRI7Gx8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109457da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build the GHZ state\n",
    "k = np.zeros((1, d**chi))\n",
    "k[:,0] = np.sqrt(1/2.)\n",
    "k[:,-1] = np.sqrt(1/2.)\n",
    "\n",
    "# feed GHZ state through model (try to reconstruct it from predicted MPS coefficients)\n",
    "real_k = Variable(torch.Tensor(k))\n",
    "k_hat = forward(real_k, model).t().data.numpy()\n",
    "\n",
    "# compare the actual state with the reconstructed state\n",
    "print(k.ravel())\n",
    "print(k_hat.ravel())\n",
    "print(k_hat.dot(k_hat.T))\n",
    "\n",
    "# mean percent error\n",
    "np_psi0_hat = psi0_hat.data.numpy()\n",
    "me = np.mean(np.abs(np_psi0 - np_psi0_hat))\n",
    "mpe = np.mean(np.abs(np_psi0 - np_psi0_hat))/1.*100\n",
    "print(\"mean error: {:.4f} \\nmean percent error: {:.4f}%\".format(me, mpe))\n",
    "\n",
    "# plot the vectors so it's easier to visualize\n",
    "f1 = plt.figure(figsize=[8,4])\n",
    "plt.subplot(211)\n",
    "plt.imshow(k) ; plt.title('true $\\psi$', fontsize=16)\n",
    "plt.clim(-.15,.85)\n",
    "plt.subplot(212)\n",
    "im = plt.imshow(k_hat) ; plt.title('reconstructed $\\psi_{MPS}$', fontsize=16)\n",
    "plt.clim(-.15,.85)\n",
    "\n",
    "cax = f1.add_axes([0.95, 0.15, 0.03, 0.7])\n",
    "cb = f1.colorbar(im, cax=cax, orientation='vertical')\n",
    "cb.set_label('color scale')\n",
    "\n",
    "plt.show() ; f1.savefig(\"./figures/psi2psi.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Inspect actual MPS coeff\n",
    "Just run the encoding portion of the autoencoder so that we can inspect how the model is encoding the GHZ state (and whether that encoding matches theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mps(X, model):\n",
    "    '''This is the encoder portion of the autencoder. It returns MPS coefficients\n",
    "    which we can inspect to see whether the models encoding matches theory'''\n",
    "    coeff = model(X, batch_size)\n",
    "    A_list = coeff2mps(coeff, d, chi)\n",
    "    return A_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the MPS coefficients for a given state and site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstate 0\n",
      "\t\tsite 0\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.09        0.97000003]\n",
      "\t\t\t [ 0.02        0.49000001]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\t\tsite 1\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.01        0.06      ]\n",
      "\t\t\t [ 0.72000003  0.02      ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\t\tsite 2\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.97000003  0.25999999]\n",
      "\t\t\t [ 0.          0.04      ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\t\tsite 3\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.93000001  0.        ]\n",
      "\t\t\t [ 0.          0.        ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 1.  0.]\n",
      "\t\t\t [ 0.  0.]]\n",
      "\tstate 1\n",
      "\t\tsite 0\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.25        0.03      ]\n",
      "\t\t\t [ 0.97000003  0.13      ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n",
      "\t\tsite 1\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.03  0.69]\n",
      "\t\t\t [ 0.05  0.1 ]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n",
      "\t\tsite 2\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.1         0.06      ]\n",
      "\t\t\t [ 0.20999999  0.94999999]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n",
      "\t\tsite 3\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.          0.        ]\n",
      "\t\t\t [ 0.          0.97000003]]\n",
      "\t\t\tmodel:\n",
      "\t\t\t[[ 0.  0.]\n",
      "\t\t\t [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# construct the ideal MPS for the GHZ state\n",
    "A_list = [] # MPS list of coefficients\n",
    "for state in range(d):\n",
    "    A_list.append([])\n",
    "    for site in range(chi):\n",
    "        A = np.zeros((d,d)) ; A[state,state] = 1\n",
    "        A_list[state].append(A)\n",
    "        \n",
    "# compare\n",
    "for j in range(d):\n",
    "    print(\"\\tstate %i\" % j)\n",
    "    for k in range(chi):\n",
    "        print(\"\\t\\tsite {}\".format(k))\n",
    "        A_i = np.around(get_mps(real_k, model)[j][k].data.numpy(), 2)\n",
    "        print('\\t\\t\\tmodel:\\n\\t\\t\\t' + str(A_i).replace('\\n', '\\n\\t\\t\\t'))\n",
    "        print('\\t\\t\\tmodel:\\n\\t\\t\\t' + str(A_list[j][k]).replace('\\n', '\\n\\t\\t\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = [7,5]\n",
    "clims = [0,1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF2CAYAAAARAIDBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJIkTAgkSRLw/wErd2oLo6FDjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c5da978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot data\n",
    "f2 = plt.figure(figsize=fs)\n",
    "f2.text(0.5, 1., 'NN coefficients for GHZ Matrix Product State', ha='center', va='center', fontsize=14)\n",
    "f2.text(0.5, 0.04, 'Site indices, $\\chi$', ha='center', va='center')\n",
    "f2.text(0.07, 0.5, 'State indices, $d$', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "v = d*100\n",
    "h = chi*10\n",
    "i = 0\n",
    "for state in range(d):\n",
    "    for site in range(chi):\n",
    "        i += 1\n",
    "        plt.subplot(v + h + i)\n",
    "        plt.title(\"$d={}$, $\\chi={}$\".format(state,site+1))\n",
    "        A_i = get_mps(real_k, model)[state][site].data.numpy()\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        im = plt.imshow(A_i)\n",
    "        plt.clim(*clims)\n",
    "        \n",
    "cax = f2.add_axes([0.95, 0.15, 0.03, 0.7])\n",
    "cb = f2.colorbar(im, cax=cax, orientation='vertical')\n",
    "cb.set_label('color scale')\n",
    "    \n",
    "plt.show() ; f2.savefig('./figures/nn-ghz-mps.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF2CAYAAAARAIDBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b6424a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot data\n",
    "f3 = plt.figure(figsize=fs)\n",
    "f3.text(0.5, 1., 'Exact coefficients for GHZ Matrix Product State', ha='center', va='center', fontsize=14)\n",
    "f3.text(0.5, 0.04, 'Site indices, $\\chi$', ha='center', va='center')\n",
    "f3.text(0.07, 0.5, 'State indices, $d$', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "v = d*100\n",
    "h = chi*10\n",
    "i = 0\n",
    "for state in range(d):\n",
    "    for site in range(chi):\n",
    "        i += 1\n",
    "        plt.subplot(v + h + i)\n",
    "        plt.title(\"$d={}$, $\\chi={}$\".format(state,site+1))\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        im = plt.imshow(A_list[state][site])\n",
    "        plt.clim(*clims)\n",
    "        \n",
    "cax = f3.add_axes([0.95, 0.15, 0.03, 0.7])\n",
    "cb = f3.colorbar(im, cax=cax, orientation='vertical')\n",
    "cb.set_label('color scale')\n",
    "    \n",
    "plt.show() ; f3.savefig('./figures/exact-ghz-mps.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
